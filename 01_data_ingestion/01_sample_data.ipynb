{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to sample a small subset of the fake news data for demonstration purposes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca392c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "input_dir = \"/home/ubuntu/upload\"\n",
    "output_dir = \"/home/ubuntu/fake_news_detection/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ba58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d4b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample size\n",
    "sample_size = 100  # 100 samples from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and sample fake news data\n",
    "fake_df = pd.read_csv(f\"{input_dir}/Fake.csv\")\n",
    "fake_sample = fake_df.sample(n=min(sample_size, len(fake_df)), random_state=42)\n",
    "fake_sample['label'] = 0  # 0 for fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and sample true news data\n",
    "true_df = pd.read_csv(f\"{input_dir}/True.csv\")\n",
    "true_sample = true_df.sample(n=min(sample_size, len(true_df)), random_state=42)\n",
    "true_sample['label'] = 1  # 1 for true news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine samples\n",
    "combined_sample = pd.concat([fake_sample, true_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33abf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the combined sample\n",
    "combined_sample = combined_sample.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined sample\n",
    "combined_sample.to_csv(f\"{output_dir}/news_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small streaming sample\n",
    "stream_sample = combined_sample.sample(n=20, random_state=42)\n",
    "stream_sample['id'] = [f\"doc_{i}\" for i in range(len(stream_sample))]\n",
    "stream_sample['timestamp'] = pd.Timestamp.now()\n",
    "stream_sample.to_csv(f\"{output_dir}/stream_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41358c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Created sample dataset with {len(combined_sample)} records\")\n",
    "print(f\"Created streaming sample with {len(stream_sample)} records\")\n",
    "print(f\"Files saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Last modified: May 29, 2025
