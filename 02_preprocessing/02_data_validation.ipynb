{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Validation Utilities for Fake News Detection\n",
    "\n",
    "This module provides utilities for validating and cleaning all columns in the fake news dataset.\n",
    "It handles null values, blank fields, and malformed data, ensuring high data quality for downstream analysis.\n",
    "\n",
    "The implementation uses Spark's distributed processing capabilities to ensure scalability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, length, trim, when, lit, regexp_replace, udf\n",
    "from pyspark.sql.types import StringType, BooleanType\n",
    "import re\n",
    "import string\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Spark session optimized for Databricks Community Edition\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FakeNewsDetection_DataValidation\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Display Spark configuration\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Shuffle partitions: {spark.conf.get('spark.sql.shuffle.partitions')}\")\n",
    "print(f\"Driver memory: {spark.conf.get('spark.driver.memory')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8611870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "from BDA02_preprocessing.data_validation_utils import DataValidator\n",
    "\n",
    "# Initialize validator\n",
    "validator = DataValidator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data\n",
    "fake_path = \"/dbfs/FileStore/tables/fake.csv\"\n",
    "true_path = \"/dbfs/FileStore/tables/true.csv\"\n",
    "\n",
    "# Check if files exist, otherwise use local paths\n",
    "if not os.path.exists(fake_path.replace(\"/dbfs\", \"\")):\n",
    "    fake_path = \"../01_data_ingestion/Fake.csv\"\n",
    "    true_path = \"../01_data_ingestion/True.csv\"\n",
    "\n",
    "# Load data with sampling for demonstration\n",
    "fake_df = spark.read.csv(fake_path, header=True, inferSchema=True).sample(0.1)\n",
    "true_df = spark.read.csv(true_path, header=True, inferSchema=True).sample(0.1)\n",
    "\n",
    "# Combine datasets with label\n",
    "fake_df = fake_df.withColumn(\"label\", lit(0))  # 0 for fake\n",
    "true_df = true_df.withColumn(\"label\", lit(1))  # 1 for true\n",
    "df = fake_df.union(true_df)\n",
    "\n",
    "# Display sample\n",
    "print(f\"Total rows: {df.count()}\")\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data quality issues\n",
    "quality_metrics = validator.analyze_data_quality(df)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Data Quality Metrics:\")\n",
    "print(\"\\nCompleteness:\")\n",
    "for column, score in quality_metrics['completeness'].items():\n",
    "    print(f\"  {column}: {score:.2f}\")\n",
    "\n",
    "print(\"\\nValidity:\")\n",
    "for column, score in quality_metrics['validity'].items():\n",
    "    print(f\"  {column}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate and clean data\n",
    "cleaned_df = validator.validate_and_clean(df)\n",
    "\n",
    "# Display cleaned data\n",
    "print(f\"Original row count: {df.count()}\")\n",
    "print(f\"Cleaned row count: {cleaned_df.count()}\")\n",
    "display(cleaned_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee91235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for data leakage in subject column\n",
    "print(\"Subject distribution by label:\")\n",
    "display(cleaned_df.groupBy(\"subject\", \"label\").count().orderBy(\"subject\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove subject column to prevent data leakage\n",
    "final_df = cleaned_df.drop(\"subject\")\n",
    "\n",
    "# Display final dataset\n",
    "print(\"Final dataset schema:\")\n",
    "final_df.printSchema()\n",
    "display(final_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validated data for next steps\n",
    "output_path = \"../processed_data/validated_data.parquet\"\n",
    "final_df.write.mode(\"overwrite\").parquet(output_path)\n",
    "print(f\"Validated data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g8ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze data quality after cleaning\n",
    "final_metrics = validator.analyze_data_quality(final_df)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Final Data Quality Metrics:\")\n",
    "print(\"\\nCompleteness:\")\n",
    "for column, score in final_metrics['completeness'].items():\n",
    "    print(f\"  {column}: {score:.2f}\")\n",
    "\n",
    "print(\"\\nValidity:\")\n",
    "for column, score in final_metrics['validity'].items():\n",
    "    print(f\"  {column}: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
