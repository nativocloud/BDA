{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b59a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Date Utilities for Fake News Detection\n",
    "\n",
    "This module provides utilities for validating, standardizing, and extracting features from date fields\n",
    "in the fake news dataset. It handles various date formats, null values, and incorrect formats,\n",
    "converting them to a standardized format and extracting useful temporal features.\n",
    "\n",
    "The implementation uses Spark's distributed processing capabilities to ensure scalability.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2f437",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import (\n",
    "    col, to_date, year, month, dayofmonth, dayofweek, \n",
    "    date_format, when, lit, regexp_replace, udf\n",
    ")\n",
    "from pyspark.sql.types import StringType, DateType, IntegerType\n",
    "from datetime import datetime\n",
    "import re\n",
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateProcessor:\n",
    "    \"\"\"\n",
    "    A class for processing date fields in a Spark DataFrame.\n",
    "    \n",
    "    This class provides methods for validating, standardizing, and extracting features\n",
    "    from date fields, handling various formats and edge cases.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, date_column: str = \"publish_date\", expected_format: str = \"MMMM d, yyyy\"):\n",
    "        \"\"\"\n",
    "        Initialize the DateProcessor.\n",
    "        \n",
    "        Args:\n",
    "            date_column (str): The name of the date column to process.\n",
    "            expected_format (str): The expected format of the date column (Spark date format).\n",
    "        \"\"\"\n",
    "        self.date_column = date_column\n",
    "        self.expected_format = expected_format\n",
    "        \n",
    "        # Common date formats to try when parsing dates\n",
    "        self.date_formats = [\n",
    "            \"MMMM d, yyyy\",       # December 25, 2017\n",
    "            \"MMM d, yyyy\",        # Dec 25, 2017\n",
    "            \"yyyy-MM-dd\",         # 2017-12-25\n",
    "            \"MM/dd/yyyy\",         # 12/25/2017\n",
    "            \"dd/MM/yyyy\",         # 25/12/2017\n",
    "            \"yyyy/MM/dd\",         # 2017/12/25\n",
    "            \"MM-dd-yyyy\",         # 12-25-2017\n",
    "            \"dd-MM-yyyy\"          # 25-12-2017\n",
    "        ]\n",
    "    \n",
    "    def validate_date_format(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Validate the date format in the DataFrame.\n",
    "        \n",
    "        This method checks if the date column values match the expected format\n",
    "        and adds a validation flag column.\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): The input DataFrame with a date column.\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with an additional validation flag column.\n",
    "        \"\"\"\n",
    "        # Create a validation flag column\n",
    "        return df.withColumn(\n",
    "            \"date_valid\",\n",
    "            when(\n",
    "                col(self.date_column).isNull(), \n",
    "                lit(False)\n",
    "            ).otherwise(\n",
    "                to_date(col(self.date_column), self.expected_format).isNotNull()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def standardize_date(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Standardize the date format in the DataFrame.\n",
    "        \n",
    "        This method attempts to parse the date column using various common formats\n",
    "        and converts it to a standard date type.\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): The input DataFrame with a date column.\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with a standardized date column.\n",
    "        \"\"\"\n",
    "        # Start with the original DataFrame\n",
    "        result_df = df\n",
    "        \n",
    "        # Try to parse the date using each format\n",
    "        for date_format in self.date_formats:\n",
    "            result_df = result_df.withColumn(\n",
    "                \"std_date\",\n",
    "                when(\n",
    "                    col(\"std_date\").isNull(),\n",
    "                    to_date(col(self.date_column), date_format)\n",
    "                ).otherwise(col(\"std_date\"))\n",
    "            )\n",
    "        \n",
    "        # For any remaining null values, use a more complex approach with UDFs\n",
    "        # This is a fallback for unusual formats\n",
    "        parse_complex_date_udf = udf(self._parse_complex_date, DateType())\n",
    "        \n",
    "        result_df = result_df.withColumn(\n",
    "            \"std_date\",\n",
    "            when(\n",
    "                col(\"std_date\").isNull() & col(self.date_column).isNotNull(),\n",
    "                parse_complex_date_udf(col(self.date_column))\n",
    "            ).otherwise(col(\"std_date\"))\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def extract_date_features(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Extract useful date features from the standardized date column.\n",
    "        \n",
    "        This method extracts year, month, day, day of week, and YYYYMMDD format\n",
    "        from the standardized date column.\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): The input DataFrame with a standardized date column.\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with additional date feature columns.\n",
    "        \"\"\"\n",
    "        # Extract date components\n",
    "        result_df = df.withColumn(\"year\", year(col(\"std_date\")))\n",
    "        result_df = result_df.withColumn(\"month\", month(col(\"std_date\")))\n",
    "        result_df = result_df.withColumn(\"day\", dayofmonth(col(\"std_date\")))\n",
    "        result_df = result_df.withColumn(\"day_of_week\", dayofweek(col(\"std_date\")))\n",
    "        \n",
    "        # Create YYYYMMDD format\n",
    "        result_df = result_df.withColumn(\n",
    "            \"date_yyyymmdd\", \n",
    "            date_format(col(\"std_date\"), \"yyyyMMdd\").cast(IntegerType())\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def process_date_column(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Process the date column in the DataFrame.\n",
    "        \n",
    "        This method combines validation, standardization, and feature extraction\n",
    "        into a single pipeline.\n",
    "        \n",
    "        Args:\n",
    "            df (DataFrame): The input DataFrame with a date column.\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with processed date columns.\n",
    "        \"\"\"\n",
    "        # Initialize the standardized date column as null\n",
    "        result_df = df.withColumn(\"std_date\", lit(None).cast(DateType()))\n",
    "        \n",
    "        # Standardize the date\n",
    "        result_df = self.standardize_date(result_df)\n",
    "        \n",
    "        # Extract date features\n",
    "        result_df = self.extract_date_features(result_df)\n",
    "        \n",
    "        # Add validation flag\n",
    "        result_df = result_df.withColumn(\n",
    "            \"date_valid\",\n",
    "            col(\"std_date\").isNotNull()\n",
    "        )\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def _parse_complex_date(self, date_str: Optional[str]) -> Optional[datetime]:\n",
    "        \"\"\"\n",
    "        Parse complex date formats that aren't handled by standard Spark functions.\n",
    "        \n",
    "        This is a Python UDF that attempts to parse dates using various approaches.\n",
    "        \n",
    "        Args:\n",
    "            date_str (str): The date string to parse.\n",
    "            \n",
    "        Returns:\n",
    "            datetime: The parsed date as a datetime object, or None if parsing fails.\n",
    "        \"\"\"\n",
    "        if not date_str:\n",
    "            return None\n",
    "        \n",
    "        # Clean the date string\n",
    "        date_str = date_str.strip()\n",
    "        \n",
    "        # Try common Python datetime formats\n",
    "        formats = [\n",
    "            \"%B %d, %Y\",      # December 25, 2017\n",
    "            \"%b %d, %Y\",      # Dec 25, 2017\n",
    "            \"%Y-%m-%d\",       # 2017-12-25\n",
    "            \"%m/%d/%Y\",       # 12/25/2017\n",
    "            \"%d/%m/%Y\",       # 25/12/2017\n",
    "            \"%Y/%m/%d\",       # 2017/12/25\n",
    "            \"%m-%d-%Y\",       # 12-25-2017\n",
    "            \"%d-%m-%Y\"        # 25-12-2017\n",
    "        ]\n",
    "        \n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                return datetime.strptime(date_str, fmt)\n",
    "            except ValueError:\n",
    "                continue\n",
    "        \n",
    "        # Try to extract date components using regex\n",
    "        # This handles formats like \"25th December 2017\" or \"December 2017\"\n",
    "        try:\n",
    "            # Extract year\n",
    "            year_match = re.search(r'\\b(19|20)\\d{2}\\b', date_str)\n",
    "            if not year_match:\n",
    "                return None\n",
    "            year = int(year_match.group(0))\n",
    "            \n",
    "            # Extract month\n",
    "            month = None\n",
    "            month_names = {\n",
    "                \"january\": 1, \"february\": 2, \"march\": 3, \"april\": 4,\n",
    "                \"may\": 5, \"june\": 6, \"july\": 7, \"august\": 8,\n",
    "                \"september\": 9, \"october\": 10, \"november\": 11, \"december\": 12,\n",
    "                \"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"jun\": 6,\n",
    "                \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12\n",
    "            }\n",
    "            \n",
    "            for name, num in month_names.items():\n",
    "                if name in date_str.lower():\n",
    "                    month = num\n",
    "                    break\n",
    "            \n",
    "            if not month:\n",
    "                # Try to find numeric month\n",
    "                month_match = re.search(r'\\b(0?[1-9]|1[0-2])\\b', date_str)\n",
    "                if month_match:\n",
    "                    month = int(month_match.group(0))\n",
    "                else:\n",
    "                    month = 1  # Default to January if no month found\n",
    "            \n",
    "            # Extract day\n",
    "            day = None\n",
    "            day_match = re.search(r'\\b(0?[1-9]|[12][0-9]|3[01])(st|nd|rd|th)?\\b', date_str)\n",
    "            if day_match:\n",
    "                day = int(re.sub(r'(st|nd|rd|th)', '', day_match.group(0)))\n",
    "            else:\n",
    "                day = 1  # Default to 1st if no day found\n",
    "            \n",
    "            return datetime(year, month, day)\n",
    "        \n",
    "        except (ValueError, TypeError):\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639563ac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def process_dates(df: DataFrame, date_column: str = \"publish_date\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Process date fields in a DataFrame.\n",
    "    \n",
    "    This function validates, standardizes, and extracts features from date fields\n",
    "    in the input DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame with a date column.\n",
    "        date_column (str): The name of the date column to process.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with processed date columns.\n",
    "    \"\"\"\n",
    "    processor = DateProcessor(date_column=date_column)\n",
    "    return processor.process_date_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7125c4f",
   "metadata": {},
   "source": [
    "Example usage:\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"DateProcessing\").getOrCreate()\n",
    "\n",
    "# Sample data with various date formats\n",
    "data = [\n",
    "    (1, \"December 25, 2017\"),\n",
    "    (2, \"Dec 25, 2017\"),\n",
    "    (3, \"2017-12-25\"),\n",
    "    (4, \"12/25/2017\"),\n",
    "    (5, \"25/12/2017\"),\n",
    "    (6, \"2017/12/25\"),\n",
    "    (7, \"12-25-2017\"),\n",
    "    (8, \"25-12-2017\"),\n",
    "    (9, \"25th December 2017\"),\n",
    "    (10, \"December 2017\"),\n",
    "    (11, None),\n",
    "    (12, \"Invalid date\")\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = spark.createDataFrame(data, [\"id\", \"publish_date\"])\n",
    "\n",
    "# Process the date column\n",
    "processed_df = process_dates(df)\n",
    "\n",
    "# Show the results\n",
    "processed_df.select(\"id\", \"publish_date\", \"std_date\", \"year\", \"month\", \"day\", \"day_of_week\", \"date_yyyymmdd\", \"date_valid\").show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Last modified: May 29, 2025
