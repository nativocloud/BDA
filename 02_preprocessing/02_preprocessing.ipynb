{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection: Data Preprocessing\n",
    "\n",
    "This notebook demonstrates the preprocessing steps for the fake news detection project, specifically tailored to the characteristics of the True.csv and Fake.csv datasets.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load the raw data from Hive tables\n",
    "2. Analyze dataset characteristics to inform preprocessing decisions\n",
    "3. Demonstrate why the 'subject' column must be dropped (data leakage)\n",
    "4. Apply dataset-specific preprocessing operations\n",
    "5. Save the preprocessed data for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our Spark session and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull, desc, expr, lit, trim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append('/dbfs/FileStore/tables')\n",
    "sys.path.append('/home/ubuntu/BDA')\n",
    "\n",
    "# Import custom modules\n",
    "from BDA.01_data_ingestion.hive_data_ingestion import HiveDataIngestion\n",
    "from BDA.02_preprocessing.enhanced_text_preprocessor import EnhancedTextPreprocessor, analyze_dataset_characteristics\n",
    "from BDA.02_preprocessing.date_utils import DateValidator\n",
    "from BDA.02_preprocessing.data_validation_utils import DataValidator\n",
    "\n",
    "# Configure Spark session optimized for Databricks Community Edition\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FakeNewsDetection_Preprocessing\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Display Spark configuration\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Shuffle partitions: {spark.conf.get('spark.sql.shuffle.partitions')}\")\n",
    "print(f\"Driver memory: {spark.conf.get('spark.driver.memory')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll load the data from the Hive tables ('fake' and 'real')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of HiveDataIngestion\n",
    "data_ingestion = HiveDataIngestion(spark)\n",
    "\n",
    "# Load data from Hive tables\n",
    "real_df, fake_df = data_ingestion.load_data_from_hive()\n",
    "\n",
    "# Display sample data\n",
    "print(\"Real news sample:\")\n",
    "display(real_df.limit(3))\n",
    "\n",
    "print(\"\\nFake news sample:\")\n",
    "display(fake_df.limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Validation\n",
    "\n",
    "Let's explore the datasets to understand their characteristics and identify preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataValidator instance\n",
    "validator = DataValidator()\n",
    "\n",
    "# Check for missing values in both datasets\n",
    "print(\"Missing values in real news dataset:\")\n",
    "validator.check_missing_values(real_df).show()\n",
    "\n",
    "print(\"\\nMissing values in fake news dataset:\")\n",
    "validator.check_missing_values(fake_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicates in real news dataset: {validator.check_duplicates(real_df)}\")\n",
    "print(f\"Duplicates in fake news dataset: {validator.check_duplicates(fake_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check text length distribution\n",
    "real_text_lengths = real_df.select(expr(\"size(split(text, ' '))\").alias(\"length\"))\n",
    "fake_text_lengths = fake_df.select(expr(\"size(split(text, ' '))\").alias(\"length\"))\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "real_lengths_pd = real_text_lengths.toPandas()\n",
    "fake_lengths_pd = fake_text_lengths.toPandas()\n",
    "\n",
    "# Plot text length distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(real_lengths_pd['length'], bins=50, alpha=0.5, label='Real News')\n",
    "plt.hist(fake_lengths_pd['length'], bins=50, alpha=0.5, label='Fake News')\n",
    "plt.xlabel('Text Length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Text Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Real news text length statistics:\")\n",
    "real_text_lengths.summary().show()\n",
    "\n",
    "print(\"\\nFake news text length statistics:\")\n",
    "fake_text_lengths.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the 'subject' Column - Data Leakage Issue\n",
    "\n",
    "Let's examine the 'subject' column in both datasets to understand why it must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check subject distribution in real news\n",
    "print(\"Subject distribution in real news:\")\n",
    "real_subjects = real_df.groupBy(\"subject\").count().orderBy(desc(\"count\"))\n",
    "display(real_subjects)\n",
    "\n",
    "# Check subject distribution in fake news\n",
    "print(\"\\nSubject distribution in fake news:\")\n",
    "fake_subjects = fake_df.groupBy(\"subject\").count().orderBy(desc(\"count\"))\n",
    "display(fake_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Leakage Visualization\n",
    "\n",
    "The analysis above reveals a critical issue: the 'subject' column perfectly discriminates between real and fake news. This creates a data leakage problem that would invalidate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataset with labels\n",
    "real_with_label = real_df.withColumn(\"label\", lit(1))\n",
    "fake_with_label = fake_df.withColumn(\"label\", lit(0))\n",
    "combined_df = real_with_label.union(fake_with_label)\n",
    "\n",
    "# Get subject distribution by label\n",
    "subject_by_label = combined_df.groupBy(\"subject\", \"label\").count().orderBy(\"subject\", \"label\")\n",
    "display(subject_by_label)\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "subject_label_pd = subject_by_label.toPandas()\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_data = subject_label_pd.pivot(index='subject', columns='label', values='count').fillna(0)\n",
    "pivot_data.columns = ['Fake News', 'Real News']\n",
    "\n",
    "# Plot the distribution\n",
    "ax = pivot_data.plot(kind='bar', figsize=(10, 6), color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('Subject Distribution by News Type')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add text labels\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why We Must Drop the 'subject' Column\n",
    "\n",
    "As demonstrated above, the 'subject' column creates a perfect data leakage problem:\n",
    "\n",
    "1. **Perfect Correlation with Labels**: \n",
    "   - Real news articles are all labeled as \"politicsNews\"\n",
    "   - Fake news articles are all labeled as \"News\"\n",
    "\n",
    "2. **Model Impact**: If we include this column:\n",
    "   - The model would achieve nearly 100% accuracy in training and validation\n",
    "   - But this accuracy would be misleading and wouldn't generalize to real-world data\n",
    "   - The model would simply learn \"if subject='politicsNews' then real, else fake\"\n",
    "\n",
    "3. **Real-World Failure**: In production, new articles wouldn't follow this artificial pattern, causing the model to make incorrect predictions based on an irrelevant feature.\n",
    "\n",
    "4. **Scientific Integrity**: Including this column would invalidate any research findings since the model wouldn't be learning meaningful patterns in the text content.\n",
    "\n",
    "Therefore, we must drop the 'subject' column from our preprocessing pipeline to ensure our model learns from the actual content of the news articles rather than this artificial distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing URL Presence\n",
    "\n",
    "Let's check for the presence of URLs in both datasets to confirm our preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check for URLs\n",
    "def contains_url(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    url_pattern = r'https?://t\\.co/\\w+|http\\S+|www\\S+|https\\S+'\n",
    "    return bool(re.search(url_pattern, text))\n",
    "\n",
    "# Register the function as a UDF\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "contains_url_udf = udf(contains_url, BooleanType())\n",
    "\n",
    "# Check URL presence in real news\n",
    "real_with_url = real_df.withColumn(\"contains_url\", contains_url_udf(col(\"text\")))\n",
    "real_url_count = real_with_url.filter(col(\"contains_url\") == True).count()\n",
    "real_total = real_df.count()\n",
    "real_url_percentage = (real_url_count / real_total) * 100\n",
    "\n",
    "# Check URL presence in fake news\n",
    "fake_with_url = fake_df.withColumn(\"contains_url\", contains_url_udf(col(\"text\")))\n",
    "fake_url_count = fake_with_url.filter(col(\"contains_url\") == True).count()\n",
    "fake_total = fake_df.count()\n",
    "fake_url_percentage = (fake_url_count / fake_total) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Real news articles containing URLs: {real_url_count} out of {real_total} ({real_url_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing URLs: {fake_url_count} out of {fake_total} ({fake_url_percentage:.2f}%)\")\n",
    "\n",
    "# Plot the results\n",
    "labels = ['Real News', 'Fake News']\n",
    "url_percentages = [real_url_percentage, fake_url_percentage]\n",
    "no_url_percentages = [100 - real_url_percentage, 100 - fake_url_percentage]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "ax.bar(x, url_percentages, width, label='Contains URLs', color='#FF6B6B')\n",
    "ax.bar(x, no_url_percentages, width, bottom=url_percentages, label='No URLs', color='#4ECDC4')\n",
    "\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('URL Presence in News Articles')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add percentage labels\n",
    "for i, v in enumerate(url_percentages):\n",
    "    ax.text(i, v/2, f\"{v:.1f}%\", ha='center', va='center', color='white', fontweight='bold')\n",
    "    ax.text(i, v + (no_url_percentages[i]/2), f\"{no_url_percentages[i]:.1f}%\", ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Social Media Content\n",
    "\n",
    "Let's check for Twitter handles and hashtags in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to check for Twitter handles and hashtags\n",
    "def contains_twitter_handle(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    pattern = r'@\\w+'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "def contains_hashtag(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    pattern = r'#\\w+'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "# Register the functions as UDFs\n",
    "contains_handle_udf = udf(contains_twitter_handle, BooleanType())\n",
    "contains_hashtag_udf = udf(contains_hashtag, BooleanType())\n",
    "\n",
    "# Check Twitter handle presence\n",
    "real_with_handle = real_df.withColumn(\"contains_handle\", contains_handle_udf(col(\"text\")))\n",
    "real_handle_count = real_with_handle.filter(col(\"contains_handle\") == True).count()\n",
    "real_handle_percentage = (real_handle_count / real_total) * 100\n",
    "\n",
    "fake_with_handle = fake_df.withColumn(\"contains_handle\", contains_handle_udf(col(\"text\")))\n",
    "fake_handle_count = fake_with_handle.filter(col(\"contains_handle\") == True).count()\n",
    "fake_handle_percentage = (fake_handle_count / fake_total) * 100\n",
    "\n",
    "# Check hashtag presence\n",
    "real_with_hashtag = real_df.withColumn(\"contains_hashtag\", contains_hashtag_udf(col(\"text\")))\n",
    "real_hashtag_count = real_with_hashtag.filter(col(\"contains_hashtag\") == True).count()\n",
    "real_hashtag_percentage = (real_hashtag_count / real_total) * 100\n",
    "\n",
    "fake_with_hashtag = fake_df.withColumn(\"contains_hashtag\", contains_hashtag_udf(col(\"text\")))\n",
    "fake_hashtag_count = fake_with_hashtag.filter(col(\"contains_hashtag\") == True).count()\n",
    "fake_hashtag_percentage = (fake_hashtag_count / fake_total) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Real news articles containing Twitter handles: {real_handle_count} out of {real_total} ({real_handle_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing Twitter handles: {fake_handle_count} out of {fake_total} ({fake_handle_percentage:.2f}%)\")\n",
    "print(f\"\\nReal news articles containing hashtags: {real_hashtag_count} out of {real_total} ({real_hashtag_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing hashtags: {fake_hashtag_count} out of {fake_total} ({fake_hashtag_percentage:.2f}%)\")\n",
    "\n",
    "# Plot the results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Twitter handles plot\n",
    "handle_percentages = [real_handle_percentage, fake_handle_percentage]\n",
    "no_handle_percentages = [100 - real_handle_percentage, 100 - fake_handle_percentage]\n",
    "\n",
    "ax1.bar(x, handle_percentages, width, label='Contains Twitter Handles', color='#FF6B6B')\n",
    "ax1.bar(x, no_handle_percentages, width, bottom=handle_percentages, label='No Twitter Handles', color='#4ECDC4')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Twitter Handle Presence in News Articles')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.legend()\n",
    "\n",
    "# Hashtags plot\n",
    "hashtag_percentages = [real_hashtag_percentage, fake_hashtag_percentage]\n",
    "no_hashtag_percentages = [100 - real_hashtag_percentage, 100 - fake_hashtag_percentage]\n",
    "\n",
    "ax2.bar(x, hashtag_percentages, width, label='Contains Hashtags', color='#FF6B6B')\n",
    "ax2.bar(x, no_hashtag_percentages, width, bottom=hashtag_percentages, label='No Hashtags', color='#4ECDC4')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.set_title('Hashtag Presence in News Articles')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Format Analysis\n",
    "\n",
    "Let's check the date formats in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DateValidator instance\n",
    "date_validator = DateValidator()\n",
    "\n",
    "# Check date formats in real news\n",
    "print(\"Date format examples in real news:\")\n",
    "display(real_df.select(\"date\").limit(5))\n",
    "\n",
    "# Check date formats in fake news\n",
    "print(\"\\nDate format examples in fake news:\")\n",
    "display(fake_df.select(\"date\").limit(5))\n",
    "\n",
    "# Check for trailing spaces in dates\n",
    "real_with_trailing = real_df.filter(expr(\"length(date) != length(trim(date))\")).count()\n",
    "fake_with_trailing = fake_df.filter(expr(\"length(date) != length(trim(date))\")).count()\n",
    "\n",
    "print(f\"\\nReal news dates with trailing spaces: {real_with_trailing} out of {real_total} ({(real_with_trailing/real_total)*100:.2f}%)\")\n",
    "print(f\"Fake news dates with trailing spaces: {fake_with_trailing} out of {fake_total} ({(fake_with_trailing/fake_total)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset-Specific Preprocessing\n",
    "\n",
    "Based on our analysis, we'll now apply dataset-specific preprocessing to address the identified issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EnhancedTextPreprocessor instance\n",
    "preprocessor = EnhancedTextPreprocessor()\n",
    "\n",
    "# Add label column to both datasets\n",
    "real_with_label = real_df.withColumn(\"label\", lit(1))\n",
    "fake_with_label = fake_df.withColumn(\"label\", lit(0))\n",
    "\n",
    "# Combine datasets\n",
    "combined_df = real_with_label.union(fake_with_label)\n",
    "\n",
    "# Apply preprocessing\n",
    "preprocessed_df = preprocessor.preprocess_spark_df(\n",
    "    combined_df, \n",
    "    text_column=\"text\", \n",
    "    title_column=\"title\", \n",
    "    combine_title_text=True\n",
    ")\n",
    "\n",
    "# Display sample of preprocessed data\n",
    "print(\"Sample of preprocessed data:\")\n",
    "display(preprocessed_df.select(\"title\", \"text\", \"processed_text\", \"label\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Let's tokenize the preprocessed text for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the preprocessed text\n",
    "tokenized_df = preprocessor.tokenize_spark_df(preprocessed_df, \"processed_text\")\n",
    "\n",
    "# Display sample of tokenized data\n",
    "print(\"Sample of tokenized data:\")\n",
    "display(tokenized_df.select(\"processed_text\", \"tokens\", \"label\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Quoted Content\n",
    "\n",
    "Let's extract quoted content from the text for additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract quoted content\n",
    "quoted_df = preprocessor.extract_quoted_content_spark_df(preprocessed_df, \"text\")\n",
    "\n",
    "# Display sample of data with quoted content\n",
    "print(\"Sample of data with extracted quoted content:\")\n",
    "display(quoted_df.select(\"text\", \"quoted_content\", \"label\").limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data\n",
    "\n",
    "Finally, let's save the preprocessed data for the feature engineering stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data\n",
    "preprocessed_df.write.mode(\"overwrite\").parquet(\"/dbfs/FileStore/fake_news_detection/preprocessed_data\")\n",
    "\n",
    "# Save tokenized data\n",
    "tokenized_df.write.mode(\"overwrite\").parquet(\"/dbfs/FileStore/fake_news_detection/tokenized_data\")\n",
    "\n",
    "# Save quoted content data\n",
    "quoted_df.write.mode(\"overwrite\").parquet(\"/dbfs/FileStore/fake_news_detection/quoted_content_data\")\n",
    "\n",
    "print(\"Preprocessed data saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing Steps\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. **Loaded and analyzed** the raw data from Hive tables\n",
    "2. **Identified dataset-specific preprocessing needs**:\n",
    "   - Demonstrated why the 'subject' column must be dropped (perfect data leakage)\n",
    "   - Confirmed the need for URL removal, especially in fake news articles\n",
    "   - Identified social media content (Twitter handles, hashtags) that requires special handling\n",
    "   - Found trailing spaces in dates that need trimming\n",
    "3. **Applied dataset-specific preprocessing**:\n",
    "   - Dropped the 'subject' column to prevent data leakage\n",
    "   - Enhanced URL removal with specific patterns for Twitter URLs\n",
    "   - Handled social media artifacts (Twitter handles, hashtags)\n",
    "   - Normalized text and trimmed whitespace\n",
    "   - Combined title and text for more comprehensive analysis\n",
    "4. **Tokenized text** for feature engineering\n",
    "5. **Extracted quoted content** for additional features\n",
    "6. **Saved preprocessed data** for the next stage of the pipeline\n",
    "\n",
    "These preprocessing steps ensure that our model will learn from the actual content of the news articles rather than artificial distinctions or irrelevant features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
