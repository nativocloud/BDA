{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abedb0d7",
   "metadata": {},
   "source": [
    "# Fake News Detection: Data Preprocessing\n",
    "\n",
    "This notebook demonstrates the preprocessing steps for the fake news detection project, specifically tailored to the characteristics of the True.csv and Fake.csv datasets.\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load the raw data from Hive tables\n",
    "2. Analyze dataset characteristics to inform preprocessing decisions\n",
    "3. Demonstrate why the 'subject' column must be dropped (data leakage)\n",
    "4. Apply dataset-specific preprocessing operations\n",
    "5. Save the preprocessed data for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617581f",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our Spark session and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, isnan, isnull, desc, expr, lit, trim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append('/dbfs/FileStore/tables')\n",
    "sys.path.append('/home/ubuntu/BDA')\n",
    "\n",
    "# Import custom modules\n",
    "from BDA.01_data_ingestion.hive_data_ingestion import HiveDataIngestion\n",
    "from BDA.02_preprocessing.enhanced_text_preprocessor import EnhancedTextPreprocessor, analyze_dataset_characteristics\n",
    "from BDA.02_preprocessing.date_utils import DateValidator\n",
    "from BDA.02_preprocessing.data_validation_utils import DataValidator\n",
    "\n",
    "# Configure Spark session optimized for Databricks Community Edition\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FakeNewsDetection_Preprocessing\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Display Spark configuration\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Shuffle partitions: {spark.conf.get('spark.sql.shuffle.partitions')}\")\n",
    "print(f\"Driver memory: {spark.conf.get('spark.driver.memory')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e143eb2",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We'll load the data from the Hive tables ('fake' and 'real')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of HiveDataIngestion\n",
    "data_ingestion = HiveDataIngestion(spark)\n",
    "\n",
    "# Load data from Hive tables\n",
    "real_df, fake_df = data_ingestion.load_data_from_hive()\n",
    "\n",
    "# Display sample data\n",
    "print(\"Real news sample:\")\n",
    "display(real_df.limit(3))\n",
    "\n",
    "print(\"\\nFake news sample:\")\n",
    "display(fake_df.limit(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0c95f",
   "metadata": {},
   "source": [
    "## Data Exploration and Validation\n",
    "\n",
    "Let's explore the datasets to understand their characteristics and identify preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff80c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataValidator instance\n",
    "validator = DataValidator()\n",
    "\n",
    "# Check for missing values in both datasets\n",
    "print(\"Missing values in real news dataset:\")\n",
    "validator.check_missing_values(real_df).show()\n",
    "\n",
    "print(\"\\nMissing values in fake news dataset:\")\n",
    "validator.check_missing_values(fake_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a775d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicates in real news dataset: {validator.check_duplicates(real_df)}\")\n",
    "print(f\"Duplicates in fake news dataset: {validator.check_duplicates(fake_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check text length distribution\n",
    "real_text_lengths = real_df.select(expr(\"size(split(text, ' '))\").alias(\"length\"))\n",
    "fake_text_lengths = fake_df.select(expr(\"size(split(text, ' '))\").alias(\"length\"))\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "real_lengths_pd = real_text_lengths.toPandas()\n",
    "fake_lengths_pd = fake_text_lengths.toPandas()\n",
    "\n",
    "# Plot text length distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(real_lengths_pd['length'], bins=50, alpha=0.5, label='Real News')\n",
    "plt.hist(fake_lengths_pd['length'], bins=50, alpha=0.5, label='Fake News')\n",
    "plt.xlabel('Text Length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Text Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Real news text length statistics:\")\n",
    "real_text_lengths.summary().show()\n",
    "\n",
    "print(\"\\nFake news text length statistics:\")\n",
    "fake_text_lengths.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc18dc",
   "metadata": {},
   "source": [
    "## Analyzing the 'subject' Column - Data Leakage Issue\n",
    "\n",
    "Let's examine the 'subject' column in both datasets to understand why it must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c315cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check subject distribution in real news\n",
    "print(\"Subject distribution in real news:\")\n",
    "real_subjects = real_df.groupBy(\"subject\").count().orderBy(desc(\"count\"))\n",
    "display(real_subjects)\n",
    "\n",
    "# Check subject distribution in fake news\n",
    "print(\"\\nSubject distribution in fake news:\")\n",
    "fake_subjects = fake_df.groupBy(\"subject\").count().orderBy(desc(\"count\"))\n",
    "display(fake_subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20ee8f",
   "metadata": {},
   "source": [
    "### Data Leakage Visualization\n",
    "\n",
    "The analysis above reveals a critical issue: the 'subject' column perfectly discriminates between real and fake news. This creates a data leakage problem that would invalidate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataset with labels\n",
    "real_with_label = real_df.withColumn(\"label\", lit(1))\n",
    "fake_with_label = fake_df.withColumn(\"label\", lit(0))\n",
    "combined_df = real_with_label.union(fake_with_label)\n",
    "\n",
    "# Get subject distribution by label\n",
    "subject_by_label = combined_df.groupBy(\"subject\", \"label\").count().orderBy(\"subject\", \"label\")\n",
    "display(subject_by_label)\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "subject_label_pd = subject_by_label.toPandas()\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_data = subject_label_pd.pivot(index='subject', columns='label', values='count').fillna(0)\n",
    "pivot_data.columns = ['Fake News', 'Real News']\n",
    "\n",
    "# Plot the distribution\n",
    "ax = pivot_data.plot(kind='bar', figsize=(10, 6), color=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('Subject Distribution by News Type')\n",
    "plt.xlabel('Subject')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add text labels\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%d')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62119cb0",
   "metadata": {},
   "source": [
    "### Why We Must Drop the 'subject' Column\n",
    "\n",
    "As demonstrated above, the 'subject' column creates a perfect data leakage problem:\n",
    "\n",
    "1. **Perfect Correlation with Labels**: \n",
    "   - Real news articles are all labeled as \"politicsNews\"\n",
    "   - Fake news articles are all labeled as \"News\"\n",
    "\n",
    "2. **Model Impact**: If we include this column:\n",
    "   - The model would achieve nearly 100% accuracy in training and validation\n",
    "   - But this accuracy would be misleading and wouldn't generalize to real-world data\n",
    "   - The model would simply learn \"if subject='politicsNews' then real, else fake\"\n",
    "\n",
    "3. **Real-World Failure**: In production, new articles wouldn't follow this artificial pattern, causing the model to make incorrect predictions based on an irrelevant feature.\n",
    "\n",
    "4. **Scientific Integrity**: Including this column would invalidate any research findings since the model wouldn't be learning meaningful patterns in the text content.\n",
    "\n",
    "Therefore, we must drop the 'subject' column from our preprocessing pipeline to ensure our model learns from the actual content of the news articles rather than this artificial distinction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ffb5d",
   "metadata": {},
   "source": [
    "## Analyzing URL Presence\n",
    "\n",
    "Let's check for the presence of URLs in both datasets to confirm our preprocessing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f62ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check for URLs\n",
    "def contains_url(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    url_pattern = r'https?://t\\.co/\\w+|http\\S+|www\\S+|https\\S+'\n",
    "    return bool(re.search(url_pattern, text))\n",
    "\n",
    "# Register the function as a UDF\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "contains_url_udf = udf(contains_url, BooleanType())\n",
    "\n",
    "# Check URL presence in real news\n",
    "real_with_url = real_df.withColumn(\"contains_url\", contains_url_udf(col(\"text\")))\n",
    "real_url_count = real_with_url.filter(col(\"contains_url\") == True).count()\n",
    "real_total = real_df.count()\n",
    "real_url_percentage = (real_url_count / real_total) * 100\n",
    "\n",
    "# Check URL presence in fake news\n",
    "fake_with_url = fake_df.withColumn(\"contains_url\", contains_url_udf(col(\"text\")))\n",
    "fake_url_count = fake_with_url.filter(col(\"contains_url\") == True).count()\n",
    "fake_total = fake_df.count()\n",
    "fake_url_percentage = (fake_url_count / fake_total) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Real news articles containing URLs: {real_url_count} out of {real_total} ({real_url_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing URLs: {fake_url_count} out of {fake_total} ({fake_url_percentage:.2f}%)\")\n",
    "\n",
    "# Plot the results\n",
    "labels = ['Real News', 'Fake News']\n",
    "url_percentages = [real_url_percentage, fake_url_percentage]\n",
    "no_url_percentages = [100 - real_url_percentage, 100 - fake_url_percentage]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "ax.bar(x, url_percentages, width, label='Contains URLs', color='#FF6B6B')\n",
    "ax.bar(x, no_url_percentages, width, bottom=url_percentages, label='No URLs', color='#4ECDC4')\n",
    "\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('URL Presence in News Articles')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Add percentage labels\n",
    "for i, v in enumerate(url_percentages):\n",
    "    ax.text(i, v/2, f\"{v:.1f}%\", ha='center', va='center', color='white', fontweight='bold')\n",
    "    ax.text(i, v + (no_url_percentages[i]/2), f\"{no_url_percentages[i]:.1f}%\", ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947ac59",
   "metadata": {},
   "source": [
    "## Analyzing Social Media Content\n",
    "\n",
    "Let's check for Twitter handles and hashtags in the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to check for Twitter handles and hashtags\n",
    "def contains_twitter_handle(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    pattern = r'@\\w+'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "def contains_hashtag(text):\n",
    "    if text is None:\n",
    "        return False\n",
    "    pattern = r'#\\w+'\n",
    "    return bool(re.search(pattern, text))\n",
    "\n",
    "# Register the functions as UDFs\n",
    "contains_handle_udf = udf(contains_twitter_handle, BooleanType())\n",
    "contains_hashtag_udf = udf(contains_hashtag, BooleanType())\n",
    "\n",
    "# Check Twitter handle presence\n",
    "real_with_handle = real_df.withColumn(\"contains_handle\", contains_handle_udf(col(\"text\")))\n",
    "real_handle_count = real_with_handle.filter(col(\"contains_handle\") == True).count()\n",
    "real_handle_percentage = (real_handle_count / real_total) * 100\n",
    "\n",
    "fake_with_handle = fake_df.withColumn(\"contains_handle\", contains_handle_udf(col(\"text\")))\n",
    "fake_handle_count = fake_with_handle.filter(col(\"contains_handle\") == True).count()\n",
    "fake_handle_percentage = (fake_handle_count / fake_total) * 100\n",
    "\n",
    "# Check hashtag presence\n",
    "real_with_hashtag = real_df.withColumn(\"contains_hashtag\", contains_hashtag_udf(col(\"text\")))\n",
    "real_hashtag_count = real_with_hashtag.filter(col(\"contains_hashtag\") == True).count()\n",
    "real_hashtag_percentage = (real_hashtag_count / real_total) * 100\n",
    "\n",
    "fake_with_hashtag = fake_df.withColumn(\"contains_hashtag\", contains_hashtag_udf(col(\"text\")))\n",
    "fake_hashtag_count = fake_with_hashtag.filter(col(\"contains_hashtag\") == True).count()\n",
    "fake_hashtag_percentage = (fake_hashtag_count / fake_total) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Real news articles containing Twitter handles: {real_handle_count} out of {real_total} ({real_handle_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing Twitter handles: {fake_handle_count} out of {fake_total} ({fake_handle_percentage:.2f}%)\")\n",
    "print(f\"\\nReal news articles containing hashtags: {real_hashtag_count} out of {real_total} ({real_hashtag_percentage:.2f}%)\")\n",
    "print(f\"Fake news articles containing hashtags: {fake_hashtag_count} out of {fake_total} ({fake_hashtag_percentage:.2f}%)\")\n",
    "\n",
    "# Plot the results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Twitter handles plot\n",
    "handle_percentages = [real_handle_percentage, fake_handle_percentage]\n",
    "no_handle_percentages = [100 - real_handle_percentage, 100 - fake_handle_percentage]\n",
    "\n",
    "ax1.bar(x, handle_percentages, width, label='Contains Twitter Handles', color='#FF6B6B')\n",
    "ax1.bar(x, no_handle_percentages, width, bottom=handle_percentages, label='No Twitter Handles', color='#4ECDC4')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Twitter Handle Presence in News Articles')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.legend()\n",
    "\n",
    "# Hashtags plot\n",
    "hashtag_percentages = [real_hashtag_percentage, fake_hashtag_percentage]\n",
    "no_hashtag_percentages = [100 - real_hashtag_percentage, 100 - fake_hashtag_percentage]\n",
    "\n",
    "ax2.bar(x, hashtag_percentages, width, label='Contains Hashtags', color='#FF6B6B')\n",
    "ax2.bar(x, no_hashtag_percentages, width, bottom=hashtag_percentages, label='No Hashtags', color='#4ECDC4')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.set_title('Hashtag Presence in News Articles')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(labels)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21349fe",
   "metadata": {},
   "source": [
    "## Applying Preprocessing\n",
    "\n",
    "Based on our analysis, we'll now apply the appropriate preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1feec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of EnhancedTextPreprocessor\n",
    "preprocessor = EnhancedTextPreprocessor()\n",
    "\n",
    "# Combine datasets with labels for preprocessing\n",
    "combined_df = combined_df.drop(\"subject\")  # Drop subject column to prevent data leakage\n",
    "\n",
    "# Apply preprocessing\n",
    "preprocessed_df = preprocessor.preprocess_text(combined_df, text_column=\"text\")\n",
    "\n",
    "# Display sample of preprocessed data\n",
    "print(\"Sample of preprocessed data:\")\n",
    "display(preprocessed_df.select(\"text\", \"processed_text\", \"label\").limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd456205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset characteristics before and after preprocessing\n",
    "original_metrics = analyze_dataset_characteristics(combined_df, \"text\")\n",
    "processed_metrics = analyze_dataset_characteristics(preprocessed_df, \"processed_text\")\n",
    "\n",
    "# Display metrics\n",
    "print(\"Original text metrics:\")\n",
    "for key, value in original_metrics.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nProcessed text metrics:\")\n",
    "for key, value in processed_metrics.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483235ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare text length before and after preprocessing\n",
    "length_comparison = preprocessed_df.select(\n",
    "    expr(\"size(split(text, ' '))\").alias(\"original_length\"),\n",
    "    expr(\"size(split(processed_text, ' '))\").alias(\"processed_length\")\n",
    ")\n",
    "\n",
    "# Convert to pandas for visualization\n",
    "length_comparison_pd = length_comparison.toPandas()\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(length_comparison_pd['original_length'], length_comparison_pd['processed_length'], \n",
    "            alpha=0.1, color='#4ECDC4')\n",
    "plt.plot([0, 2000], [0, 2000], 'r--', alpha=0.7)  # Diagonal line for reference\n",
    "plt.xlabel('Original Text Length (words)')\n",
    "plt.ylabel('Processed Text Length (words)')\n",
    "plt.title('Text Length Comparison: Before vs After Preprocessing')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2000)\n",
    "plt.show()\n",
    "\n",
    "# Calculate average reduction in text length\n",
    "avg_original = length_comparison_pd['original_length'].mean()\n",
    "avg_processed = length_comparison_pd['processed_length'].mean()\n",
    "reduction_percentage = ((avg_original - avg_processed) / avg_original) * 100\n",
    "\n",
    "print(f\"Average original text length: {avg_original:.2f} words\")\n",
    "print(f\"Average processed text length: {avg_processed:.2f} words\")\n",
    "print(f\"Average reduction: {reduction_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e924e753",
   "metadata": {},
   "source": [
    "## Save Preprocessed Data\n",
    "\n",
    "Finally, let's save the preprocessed data for the next steps in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd5001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data\n",
    "output_path = \"../processed_data/preprocessed_data.parquet\"\n",
    "preprocessed_df.write.mode(\"overwrite\").parquet(output_path)\n",
    "print(f\"Preprocessed data saved to {output_path}\")\n",
    "\n",
    "# Also save a sample for quick testing\n",
    "sample_path = \"../processed_data/preprocessed_sample.parquet\"\n",
    "preprocessed_df.sample(0.1).write.mode(\"overwrite\").parquet(sample_path)\n",
    "print(f\"Sample preprocessed data saved to {sample_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f8e6d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. Loaded and explored the fake news dataset\n",
    "2. Identified and addressed the data leakage issue with the 'subject' column\n",
    "3. Analyzed text characteristics including URLs, Twitter handles, and hashtags\n",
    "4. Applied comprehensive text preprocessing\n",
    "5. Saved the preprocessed data for feature engineering\n",
    "\n",
    "The preprocessing steps were specifically tailored to the characteristics of this dataset, ensuring that our models will learn from meaningful patterns in the text rather than artificial distinctions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
