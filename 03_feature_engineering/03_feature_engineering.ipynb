{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Fake News Detection\n",
    "\n",
    "This notebook focuses on feature engineering for the fake news detection pipeline, operating on the complete preprocessed dataset. Feature engineering involves creating new features from existing data to improve model performance.\n",
    "\n",
    "## Why Feature Engineering is Important\n",
    "\n",
    "In fake news detection, feature engineering helps to:\n",
    "1. Extract meaningful signals from text (e.g., readability, sentiment)\n",
    "2. Capture metadata characteristics (e.g., source, topic)\n",
    "3. Create numerical representations suitable for machine learning models\n",
    "\n",
    "This notebook demonstrates extracting metadata features (like source) and performing topic modeling using Spark MLlib for scalability on the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import necessary libraries and set up the Spark environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lower, regexp_extract, when, count, desc, lit, array\n",
    "from pyspark.sql.types import StringType, ArrayType, StructType, StructField\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer, StopWordsRemover, LDA\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Timer and Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082348a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for Databricks DBFS\n",
    "processed_data_path = \"dbfs:/FileStore/fake_news_detection/data/processed_data/processed_news.parquet\"\n",
    "feature_data_path = \"dbfs:/FileStore/fake_news_detection/data/feature_data/features.parquet\"\n",
    "results_dir = \"dbfs:/FileStore/fake_news_detection/logs\"\n",
    "model_save_dir = \"dbfs:/FileStore/fake_news_detection/models/feature_engineering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec0f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don\"t exist using dbutils\n",
    "dbutils.fs.mkdirs(feature_data_path.replace(\"dbfs:\", \"\").rsplit(\"/\", 1)[0])\n",
    "dbutils.fs.mkdirs(results_dir.replace(\"dbfs:\", \"\"))\n",
    "dbutils.fs.mkdirs(model_save_dir.replace(\"dbfs:\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b398f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session with Hive support, configured for the full dataset\n",
    "# For Databricks Community Edition, use more conservative settings\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FakeNewsFeatureEngineering\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data\n",
    "\n",
    "Load the full preprocessed dataset saved in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_processed_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading preprocessed data from {processed_data_path}...\")\n",
    "try:\n",
    "    processed_df = spark.read.parquet(processed_data_path)\n",
    "    print(f\"Successfully loaded {processed_df.count()} records.\")\n",
    "    processed_df.printSchema()\n",
    "    \n",
    "    # Cache the DataFrame for better performance\n",
    "    processed_df.cache()\n",
    "    print(\"Preprocessed DataFrame cached.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading preprocessed data: {e}\")\n",
    "    print(\"Please ensure the preprocessing notebook ran successfully and saved data to the correct path.\")\n",
    "    # Optionally stop execution if data loading fails\n",
    "    # spark.stop()\n",
    "    # raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Extracting News Source\n",
    "\n",
    "We will attempt to extract the news source from the beginning of the text, often formatted like \"WASHINGTON (Reuters) - ...\". We will use Spark UDFs for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of common news sources\n",
    "common_sources = [\n",
    "    \"Reuters\", \"AP\", \"Associated Press\", \"CNN\", \"Fox News\", \"MSNBC\", \"BBC\", \n",
    "    \"New York Times\", \"Washington Post\", \"USA Today\", \"NPR\", \"CBS\", \"NBC\", \n",
    "    \"ABC News\", \"The Guardian\", \"Bloomberg\", \"Wall Street Journal\", \"WSJ\",\n",
    "    \"Huffington Post\", \"Breitbart\", \"BuzzFeed\", \"Daily Mail\", \"The Hill\"\n",
    "]\n",
    "\n",
    "# Function to extract source using regex\n",
    "def extract_source_from_text(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    # Pattern: Optional Location (SOURCE) - Text\n",
    "    match = re.match(r\"^\\s*\\w*\\s*\\(([^)]+)\\)\\s*-\", text)\n",
    "    if match:\n",
    "        potential_source = match.group(1).strip()\n",
    "        # Check against common sources\n",
    "        for src in common_sources:\n",
    "            if src.lower() == potential_source.lower():\n",
    "                return src\n",
    "        # If not a common source but pattern matches, return it\n",
    "        # return potential_source \n",
    "    \n",
    "    # Fallback: Check if text starts with a known source name\n",
    "    for src in common_sources:\n",
    "        if text.lower().startswith(src.lower()):\n",
    "            return src\n",
    "            \n",
    "    return None\n",
    "\n",
    "# Register UDF\n",
    "extract_source_udf = udf(extract_source_from_text, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2abc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UDF to extract source\n",
    "print(\"Extracting news source feature...\")\n",
    "if \"processed_df\" in locals():\n",
    "    features_df = processed_df.withColumn(\"extracted_source\", extract_source_udf(col(\"text\")))\n",
    "    \n",
    "    # Show some results\n",
    "    features_df.select(\"text\", \"extracted_source\").show(10, truncate=80)\n",
    "    \n",
    "    # Analyze extracted sources\n",
    "    print(\"\\nDistribution of extracted sources:\")\n",
    "    source_counts = features_df.groupBy(\"extracted_source\").count().orderBy(desc(\"count\"))\n",
    "    source_counts.show()\n",
    "    \n",
    "    # Analyze source distribution by label\n",
    "    print(\"\\nExtracted source distribution by label:\")\n",
    "    source_by_label = features_df.groupBy(\"extracted_source\", \"label\").count()\n",
    "    source_by_label_pivot = source_by_label.groupBy(\"extracted_source\")\\\n",
    "        .pivot(\"label\", [0, 1])\\\n",
    "        .agg(count(\"count\").alias(\"count\"))\\\n",
    "        .na.fill(0)\\\n",
    "        .withColumnRenamed(\"0\", \"fake_count\")\\\n",
    "        .withColumnRenamed(\"1\", \"real_count\")\\\n",
    "        .withColumn(\"total_count\", col(\"fake_count\") + col(\"real_count\"))\\\n",
    "        .orderBy(desc(\"total_count\"))\n",
    "        \n",
    "    source_by_label_pivot.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Error: processed_df not loaded. Cannot extract features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Topic Modeling with Spark MLlib\n",
    "\n",
    "We will use Latent Dirichlet Allocation (LDA) from Spark MLlib to discover latent topics in the news articles. This requires text tokenization and vectorization first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic_modeling_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the DataFrame is available\n",
    "if \"features_df\" in locals():\n",
    "    print(\"Setting up topic modeling pipeline...\")\n",
    "    \n",
    "    # 1. Tokenizer: Split processed text into words\n",
    "    tokenizer = Tokenizer(inputCol=\"processed_text\", outputCol=\"raw_tokens\")\n",
    "    \n",
    "    # 2. StopWordsRemover: Remove common English stop words\n",
    "    remover = StopWordsRemover(inputCol=\"raw_tokens\", outputCol=\"tokens\")\n",
    "    \n",
    "    # 3. CountVectorizer: Convert tokens into frequency vectors\n",
    "    # Adjust vocabSize, minDF based on dataset size and analysis\n",
    "    cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"rawFeatures\", vocabSize=10000, minDF=5.0)\n",
    "    \n",
    "    # 4. IDF: Down-weight common terms across documents\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    \n",
    "    # 5. LDA: Discover latent topics\n",
    "    # Adjust k (number of topics) based on exploration\n",
    "    lda = LDA(k=10, maxIter=10, featuresCol=\"features\", topicDistributionCol=\"topicDistribution\")\n",
    "    \n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, lda])\n",
    "    \n",
    "    print(\"Topic modeling pipeline created.\")\n",
    "else:\n",
    "    print(\"Error: features_df not available. Cannot set up topic modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic_modeling_run",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the data\n",
    "if \"pipeline\" in locals() and \"features_df\" in locals():\n",
    "    print(\"Fitting topic modeling pipeline... This may take some time on the full dataset.\")\n",
    "    start_lda_time = time.time()\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline_model = pipeline.fit(features_df)\n",
    "    \n",
    "    # Transform the data to get topic distributions\n",
    "    lda_results_df = pipeline_model.transform(features_df)\n",
    "    \n",
    "    print(f\"Pipeline fitting and transformation completed in {time.time() - start_lda_time:.2f} seconds.\")\n",
    "    \n",
    "    # Display schema with new columns\n",
    "    lda_results_df.printSchema()\n",
    "    \n",
    "    # Show sample results with topic distribution\n",
    "    lda_results_df.select(\"id\", \"label\", \"topicDistribution\").show(5, truncate=False)\n",
    "    \n",
    "    # Save the pipeline model for later use\n",
    "    pipeline_model_path = f\"{model_save_dir}/lda_pipeline_model\"\n",
    "    print(f\"Saving LDA pipeline model to {pipeline_model_path}...\")\n",
    "    pipeline_model.write().overwrite().save(pipeline_model_path)\n",
    "    print(\"LDA pipeline model saved.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Error: Pipeline or features_df not available. Cannot run topic modeling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Topics\n",
    "\n",
    "Let's examine the topics discovered by the LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_topics",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"pipeline_model\" in locals():\n",
    "    print(\"Analyzing discovered topics...\")\n",
    "    \n",
    "    # Extract the LDA model and vocabulary from the pipeline\n",
    "    lda_model = pipeline_model.stages[-1] # LDA is the last stage\n",
    "    cv_model = pipeline_model.stages[2] # CountVectorizer is the third stage\n",
    "    vocabulary = cv_model.vocabulary\n",
    "    \n",
    "    # Get the topic descriptions (top words per topic)\n",
    "    topics = lda_model.describeTopics(maxTermsPerTopic=10)\n",
    "    \n",
    "    print(\"Top terms per topic:\")\n",
    "    topics_with_terms = []\n",
    "    for row in topics.collect():\n",
    "        topic_idx = row[0]\n",
    "        term_indices = row[1]\n",
    "        term_weights = row[2]\n",
    "        topic_terms = [vocabulary[i] for i in term_indices]\n",
    "        print(f\"Topic {topic_idx}: {topic_terms}\")\n",
    "        \n",
    "        # Create a row for the topics DataFrame\n",
    "        topics_with_terms.append((topic_idx, topic_terms))\n",
    "    \n",
    "    # Convert topics summary to DataFrame for easier analysis/saving\n",
    "    topics_schema = StructType([\n",
    "        StructField(\"topic_id\", StringType(), False),\n",
    "        StructField(\"top_terms\", ArrayType(StringType()), False)\n",
    "    ])\n",
    "    \n",
    "    # Create DataFrame using createDataFrame with explicit schema\n",
    "    topics_df = spark.createDataFrame(topics_with_terms, [\"topic_id\", \"top_terms\"])\n",
    "    topics_df.show(truncate=False)\n",
    "    \n",
    "    # Save topics summary\n",
    "    topics_save_path = f\"{results_dir}/lda_topics_summary.parquet\"\n",
    "    print(f\"Saving topics summary to {topics_save_path}...\")\n",
    "    topics_df.write.mode(\"overwrite\").parquet(topics_save_path)\n",
    "    print(\"Topics summary saved.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Error: LDA pipeline model not available. Cannot analyze topics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Feature Distributions (Using Databricks Native Visualization)\n",
    "\n",
    "Let's visualize the distribution of the extracted source feature using Databricks native visualization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"source_by_label_pivot\" in locals():\n",
    "    print(\"Visualizing extracted source distribution...\")\n",
    "    \n",
    "    # Limit to top N sources for better visualization\n",
    "    top_n = 15\n",
    "    top_sources_df = source_by_label_pivot.limit(top_n)\n",
    "    \n",
    "    # Use Databricks display function for native visualization\n",
    "    print(f\"Distribution of Fake vs Real News by Top {top_n} Extracted Sources:\")\n",
    "    display(top_sources_df)\n",
    "    \n",
    "    # Save the data for future reference\n",
    "    source_dist_path = f\"{results_dir}/source_distribution.parquet\"\n",
    "    top_sources_df.write.mode(\"overwrite\").parquet(source_dist_path)\n",
    "    print(f\"Source distribution data saved to {source_dist_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Source distribution data not available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Topic Distribution by Label\n",
    "\n",
    "Let's analyze how topics are distributed across fake and real news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "topic_distribution_by_label",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"lda_results_df\" in locals():\n",
    "    print(\"Analyzing topic distribution by label...\")\n",
    "    \n",
    "    # First, we need to extract the dominant topic for each document\n",
    "    from pyspark.sql.functions import udf, array_position, array, lit, greatest\n",
    "    from pyspark.sql.types import IntegerType\n",
    "    \n",
    "    # UDF to find the index of the maximum value in the topic distribution vector\n",
    "    @udf(returnType=IntegerType())\n",
    "    def get_dominant_topic(topic_dist):\n",
    "        return int(topic_dist.argmax())\n",
    "    \n",
    "    # Add dominant topic column\n",
    "    topic_label_df = lda_results_df.withColumn(\"dominant_topic\", get_dominant_topic(col(\"topicDistribution\")))\n",
    "    \n",
    "    # Count documents by dominant topic and label\n",
    "    topic_label_counts = topic_label_df.groupBy(\"dominant_topic\", \"label\").count()\n",
    "    \n",
    "    # Pivot to get fake vs real counts per topic\n",
    "    topic_label_pivot = topic_label_counts.groupBy(\"dominant_topic\")\\\n",
    "        .pivot(\"label\", [0, 1])\\\n",
    "        .agg(count(\"count\").alias(\"count\"))\\\n",
    "        .na.fill(0)\\\n",
    "        .withColumnRenamed(\"0\", \"fake_count\")\\\n",
    "        .withColumnRenamed(\"1\", \"real_count\")\\\n",
    "        .withColumn(\"total_count\", col(\"fake_count\") + col(\"real_count\"))\\\n",
    "        .withColumn(\"fake_ratio\", col(\"fake_count\") / col(\"total_count\"))\\\n",
    "        .withColumn(\"real_ratio\", col(\"real_count\") / col(\"total_count\"))\\\n",
    "        .orderBy(\"dominant_topic\")\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"Topic distribution by label:\")\n",
    "    display(topic_label_pivot)\n",
    "    \n",
    "    # Save the results\n",
    "    topic_dist_path = f\"{results_dir}/topic_distribution_by_label.parquet\"\n",
    "    topic_label_pivot.write.mode(\"overwrite\").parquet(topic_dist_path)\n",
    "    print(f\"Topic distribution by label saved to {topic_dist_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"LDA results not available. Cannot analyze topic distribution by label.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Features and Saving Results\n",
    "\n",
    "Let's combine all the features we've extracted and save the final feature dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combine_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"lda_results_df\" in locals() and \"features_df\" in locals():\n",
    "    print(\"Combining features and saving results...\")\n",
    "    \n",
    "    # Select relevant columns from LDA results\n",
    "    lda_features = lda_results_df.select(\"id\", \"topicDistribution\")\n",
    "    \n",
    "    # Join with the features DataFrame\n",
    "    combined_features = features_df.join(lda_features, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Show the schema of the combined features\n",
    "    print(\"Combined features schema:\")\n",
    "    combined_features.printSchema()\n",
    "    \n",
    "    # Show a sample of the combined features\n",
    "    print(\"\\nSample of combined features:\")\n",
    "    combined_features.select(\"id\", \"label\", \"extracted_source\", \"topicDistribution\").show(5, truncate=False)\n",
    "    \n",
    "    # Save the combined features\n",
    "    print(f\"Saving combined features to {feature_data_path}...\")\n",
    "    combined_features.write.mode(\"overwrite\").parquet(feature_data_path)\n",
    "    print(\"Combined features saved.\")\n",
    "    \n",
    "    # Also save as a Hive table for easy access\n",
    "    combined_features.write.mode(\"overwrite\").saveAsTable(\"fake_news_features\")\n",
    "    print(\"Combined features also saved as Hive table 'fake_news_features'.\")\n",
    "    \n",
    "else:\n",
    "    print(\"LDA results or features DataFrame not available. Cannot combine features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Cleanup\n",
    "\n",
    "Let's clean up cached DataFrames to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory_cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpersist cached DataFrames\n",
    "if \"processed_df\" in locals():\n",
    "    processed_df.unpersist()\n",
    "    print(\"Unpersisted processed_df.\")\n",
    "    \n",
    "if \"lda_results_df\" in locals() and hasattr(lda_results_df, \"unpersist\"):\n",
    "    lda_results_df.unpersist()\n",
    "    print(\"Unpersisted lda_results_df.\")\n",
    "    \n",
    "print(\"Memory cleaned up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Summary\n",
    "\n",
    "Let's summarize the execution time and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "execution_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total execution time\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "\n",
    "# Summarize what we've done\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(\"1. Extracted news source from text\")\n",
    "print(\"2. Performed topic modeling using LDA\")\n",
    "print(\"3. Analyzed topic distribution by label\")\n",
    "print(\"4. Combined features and saved results\")\n",
    "\n",
    "# List saved artifacts\n",
    "print(\"\\nSaved Artifacts:\")\n",
    "print(f\"- Combined features: {feature_data_path}\")\n",
    "print(f\"- LDA pipeline model: {model_save_dir}/lda_pipeline_model\")\n",
    "print(f\"- Topic summary: {results_dir}/lda_topics_summary.parquet\")\n",
    "print(f\"- Source distribution: {results_dir}/source_distribution.parquet\")\n",
    "print(f\"- Topic distribution by label: {results_dir}/topic_distribution_by_label.parquet\")\n",
    "print(\"- Hive table: fake_news_features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# Last modified: May 29, 2025
