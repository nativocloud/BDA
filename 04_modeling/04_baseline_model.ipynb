{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to implement and run a simplified baseline model for fake news detection.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92dd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aaf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d634f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = \"/home/ubuntu/fake_news_detection/data\"\n",
    "models_dir = \"/home/ubuntu/fake_news_detection/models\"\n",
    "results_dir = \"/home/ubuntu/fake_news_detection/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38124e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "# Load the sampled data\n",
    "df = pd.read_csv(f\"{data_dir}/news_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "print(\"Preprocessing text...\")\n",
    "# Fill NaN values\n",
    "df['text'] = df['text'].fillna('')\n",
    "if 'title' in df.columns:\n",
    "    df['title'] = df['title'].fillna('')\n",
    "    # Combine title and text for better context\n",
    "    df['content'] = df['title'] + \" \" + df['text']\n",
    "else:\n",
    "    df['content'] = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daaa635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "df['content'] = df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Class distribution:\\n{df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "print(\"Splitting data...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['content'], df['label'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cba272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction with TF-IDF\n",
    "print(\"Extracting features...\")\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f184a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest classifier\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf448b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "y_pred = rf_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluating model...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8afdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37424843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and vectorizer\n",
    "print(\"Saving model and vectorizer...\")\n",
    "import pickle\n",
    "with open(f\"{models_dir}/rf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "with open(f\"{models_dir}/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31996558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    \"model\": \"Random Forest\",\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1,\n",
    "    \"report\": report,\n",
    "    \"execution_time\": time.time() - start_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{results_dir}/baseline_results.txt\", \"w\") as f:\n",
    "    f.write(f\"Model: {results['model']}\\n\")\n",
    "    f.write(f\"Accuracy: {results['accuracy']:.4f}\\n\")\n",
    "    f.write(f\"Precision: {results['precision']:.4f}\\n\")\n",
    "    f.write(f\"Recall: {results['recall']:.4f}\\n\")\n",
    "    f.write(f\"F1 Score: {results['f1']:.4f}\\n\")\n",
    "    f.write(f\"Execution Time: {results['execution_time']:.2f} seconds\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualization of the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "values = [accuracy, precision, recall, f1]\n",
    "sns.barplot(x=metrics, y=values)\n",
    "plt.title('Random Forest Model Performance')\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"{results_dir}/baseline_performance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d432f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results saved to {results_dir}\")\n",
    "print(f\"Total execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4be322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "})\n",
    "top_features = feature_importance.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecaa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='importance', y='feature', data=top_features)\n",
    "plt.title('Top 20 Important Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1accfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importance visualization saved.\")\n",
    "print(\"Baseline model implementation completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
