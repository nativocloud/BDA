{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model for Fake News Detection\n",
    "\n",
    "Este notebook implementa uma rede neural Long Short-Term Memory (LSTM) para deteção de notícias falsas. As redes LSTM são particularmente eficazes para dados sequenciais como texto, pois conseguem capturar dependências de longo alcance e informação contextual.\n",
    "\n",
    "## Porquê LSTM para Deteção de Notícias Falsas?\n",
    "\n",
    "As redes LSTM oferecem várias vantagens para tarefas de classificação de texto:\n",
    "1. Capturam padrões sequenciais e dependências no texto\n",
    "2. Mantêm memória de partes anteriores do texto ao processar partes posteriores\n",
    "3. Conseguem aprender padrões linguísticos complexos que podem indicar deceção\n",
    "\n",
    "## Considerações para Databricks Community Edition\n",
    "\n",
    "**IMPORTANTE**: Este notebook inclui estratégias para lidar com as limitações da Databricks Community Edition:\n",
    "- Memória limitada (15.3 GB)\n",
    "- Apenas 2 cores de processamento\n",
    "- Tempo de execução limitado (desligamento após período de inatividade)\n",
    "\n",
    "Dependendo dos recursos disponíveis, pode optar por:\n",
    "1. **Dataset completo**: Para resultados ótimos (requer mais recursos)\n",
    "2. **Amostragem estratificada**: Para desenvolvimento e testes rápidos\n",
    "3. **Validação cruzada**: Para avaliação robusta mesmo com amostras menores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup e Imports\n",
    "\n",
    "Primeiro, vamos importar as bibliotecas necessárias e configurar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, udf, lit\n",
    "from pyspark.sql.types import StringType, ArrayType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar Estrutura de Diretórios\n",
    "\n",
    "Configurar os diretórios necessários para armazenar modelos, logs e resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory_structure():\n",
    "    \"\"\"Criar estrutura de diretórios para modelos e logs no DBFS.\n",
    "    \n",
    "    Esta função cria os diretórios necessários para armazenar:\n",
    "    - Modelos: Modelos LSTM treinados e tokenizadores\n",
    "    - Logs: Métricas de desempenho e visualizações\n",
    "    - Validação cruzada: Resultados de cada fold\n",
    "    \"\"\"\n",
    "    # No Databricks, usamos dbutils para interagir com o DBFS\n",
    "    directories = [\n",
    "        \"dbfs:/FileStore/fake_news_detection/models/lstm\",\n",
    "        \"dbfs:/FileStore/fake_news_detection/logs\",\n",
    "        \"dbfs:/FileStore/fake_news_detection/models/lstm/cv_folds\"\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        # Remover prefixo dbfs: para dbutils.fs.mkdirs\n",
    "        dir_path = directory.replace(\"dbfs:\", \"\")\n",
    "        dbutils.fs.mkdirs(dir_path)\n",
    "        print(f\"Diretório criado: {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializar Sessão Spark\n",
    "\n",
    "Criar uma sessão Spark com configuração apropriada para a Databricks Community Edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_spark():\n",
    "    \"\"\"Inicializar uma sessão Spark com configuração otimizada para Databricks Community Edition.\"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"FakeNewsLSTM\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "        .config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    print(f\"Versão do Spark: {spark.version}\")\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar e Preparar Dados\n",
    "\n",
    "Carregar os dados pré-processados da etapa de engenharia de características. Para o treino do LSTM, oferecemos opções para usar o dataset completo ou uma amostra estratificada, dependendo dos recursos disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(spark, use_sample=False, sample_size_per_class=None):\n",
    "    \"\"\"Carregar dados pré-processados da etapa de engenharia de características.\n",
    "    \n",
    "    Args:\n",
    "        spark: Objeto SparkSession\n",
    "        use_sample: Se True, usa amostragem estratificada para treino com recursos limitados\n",
    "        sample_size_per_class: Número de registros por classe para a amostra (se None e use_sample=True, usa 5000)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Spark DataFrame contendo os dados\n",
    "    \"\"\"\n",
    "    # Definir caminhos\n",
    "    feature_data_path = \"dbfs:/FileStore/fake_news_detection/data/feature_data/features.parquet\"\n",
    "    processed_data_path = \"dbfs:/FileStore/fake_news_detection/data/processed_data/processed_news.parquet\"\n",
    "    \n",
    "    print(\"Carregando dados...\")\n",
    "    try:\n",
    "        # Tentar carregar primeiro da saída de engenharia de características\n",
    "        df = spark.read.parquet(feature_data_path)\n",
    "        print(f\"Dados com características carregados de {feature_data_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Não foi possível carregar dados com características: {e}\")\n",
    "        # Recorrer a dados processados\n",
    "        try:\n",
    "            df = spark.read.parquet(processed_data_path)\n",
    "            print(f\"Dados processados carregados de {processed_data_path}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Não foi possível carregar dados processados: {e2}\")\n",
    "            # Último recurso: tentar tabelas Hive\n",
    "            try:\n",
    "                df = spark.table(\"processed_news\")\n",
    "                print(\"Dados carregados da tabela Hive 'processed_news'\")\n",
    "            except Exception as e3:\n",
    "                print(f\"Erro ao carregar dados de todas as fontes: {e3}\")\n",
    "                print(\"Saindo pois nenhuma fonte de dados está disponível.\")\n",
    "                return None\n",
    "    \n",
    "    # Imprimir informações do dataset\n",
    "    total_count = df.count()\n",
    "    print(f\"Total de registros: {total_count}\")\n",
    "    print(\"Distribuição de classes:\")\n",
    "    class_counts = df.groupBy(\"label\").count()\n",
    "    class_counts.show()\n",
    "    \n",
    "    # Verificar recursos disponíveis\n",
    "    print(\"\\nVerificando recursos disponíveis...\")\n",
    "    import psutil\n",
    "    available_memory_gb = psutil.virtual_memory().available / (1024 ** 3)\n",
    "    print(f\"Memória disponível: {available_memory_gb:.2f} GB\")\n",
    "    \n",
    "    # Criar amostra estratificada se solicitado ou se o dataset for muito grande para os recursos disponíveis\n",
    "    if use_sample:\n",
    "        if sample_size_per_class is None:\n",
    "            # Valor padrão para amostra na Community Edition\n",
    "            sample_size_per_class = 5000\n",
    "            \n",
    "        print(f\"\\nCriando amostra estratificada com {sample_size_per_class} registros por classe...\")\n",
    "        \n",
    "        # Obter contagens por classe\n",
    "        class_counts_dict = {row['label']: row['count'] for row in class_counts.collect()}\n",
    "        \n",
    "        # Calcular frações para amostragem estratificada\n",
    "        fractions = {}\n",
    "        for label, count in class_counts_dict.items():\n",
    "            fractions[label] = min(1.0, sample_size_per_class / count)\n",
    "        \n",
    "        # Criar amostra estratificada\n",
    "        df = df.sampleBy(\"label\", fractions=fractions, seed=42)\n",
    "        \n",
    "        print(\"Amostra criada. Nova distribuição de classes:\")\n",
    "        df.groupBy(\"label\").count().show()\n",
    "        \n",
    "        print(\"\\nNOTA: Usando amostra estratificada devido a limitações de recursos.\")\n",
    "        print(\"Para resultados ótimos, considere usar o dataset completo se tiver recursos suficientes.\")\n",
    "    else:\n",
    "        # Verificar se o dataset completo é viável para os recursos disponíveis\n",
    "        estimated_memory_needed_gb = total_count * 0.001  # Estimativa grosseira: ~1MB por registro\n",
    "        if estimated_memory_needed_gb > available_memory_gb * 0.7:  # Usar no máximo 70% da memória disponível\n",
    "            print(\"\\nAVISO: O dataset completo pode exceder a memória disponível.\")\n",
    "            print(\"Considere usar amostragem estratificada (use_sample=True) para evitar problemas de memória.\")\n",
    "            print(\"Continuando com o dataset completo, mas monitore o uso de memória.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar Dados de Texto para LSTM\n",
    "\n",
    "Processar os dados de texto para um formato adequado para treino LSTM, incluindo tokenização e padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_data(df, text_column=\"processed_text\", max_words=20000, max_len=300):\n",
    "    \"\"\"Preparar dados de texto para modelo LSTM através de tokenização e padding.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame Pandas contendo os dados de texto\n",
    "        text_column: Nome da coluna contendo o texto a processar\n",
    "        max_words: Número máximo de palavras no vocabulário\n",
    "        max_len: Comprimento máximo das sequências\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X_train_pad, X_test_pad, y_train, y_test, tokenizer)\n",
    "    \"\"\"\n",
    "    print(\"Preparando dados de texto para LSTM...\")\n",
    "    \n",
    "    # Preencher valores NaN\n",
    "    df[text_column] = df[text_column].fillna('')\n",
    "    \n",
    "    # Dividir dados com estratificação\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[text_column], \n",
    "        df['label'], \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    print(f\"Tamanho do conjunto de treino: {len(X_train)}\")\n",
    "    print(f\"Tamanho do conjunto de teste: {len(X_test)}\")\n",
    "    \n",
    "    # Tokenizar texto\n",
    "    print(\"Tokenizando texto...\")\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    \n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    \n",
    "    # Padding de sequências\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "    \n",
    "    print(f\"Tamanho do vocabulário: {min(len(tokenizer.word_index) + 1, max_words)}\")\n",
    "    print(f\"Comprimento da sequência: {max_len}\")\n",
    "    \n",
    "    return X_train_pad, X_test_pad, y_train, y_test, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir Modelo LSTM\n",
    "\n",
    "Criar uma arquitetura de modelo LSTM bidirecional para classificação de texto, com opções para ajustar a complexidade baseada nos recursos disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(vocab_size, embedding_dim=100, max_len=300, complexity=\"standard\"):\n",
    "    \"\"\"Construir um modelo LSTM bidirecional para classificação de texto.\n",
    "    \n",
    "    Args:\n",
    "        vocab_size: Tamanho do vocabulário\n",
    "        embedding_dim: Dimensão da camada de embedding\n",
    "        max_len: Comprimento máximo das sequências de entrada\n",
    "        complexity: Nível de complexidade do modelo (\"light\", \"standard\", \"deep\")\n",
    "        \n",
    "    Returns:\n",
    "        model: Modelo Keras compilado\n",
    "    \"\"\"\n",
    "    print(f\"Construindo modelo LSTM bidirecional (complexidade: {complexity})...\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "    \n",
    "    if complexity == \"light\":  # Modelo leve para recursos limitados\n",
    "        model.add(Bidirectional(LSTM(units=64, return_sequences=False)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    elif complexity == \"standard\":  # Modelo padrão (bom equilíbrio)\n",
    "        model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Bidirectional(LSTM(units=64, return_sequences=False)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    else:  # Modelo profundo para recursos abundantes\n",
    "        model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Bidirectional(LSTM(units=64, return_sequences=False)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # Camada de saída (comum a todos os modelos)\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar com Validação Cruzada\n",
    "\n",
    "Treinar o modelo LSTM usando validação cruzada k-fold para uma avaliação mais robusta, especialmente importante quando se trabalha com amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_cross_validation(X, y, vocab_size, embedding_dim=100, max_len=300, n_folds=5, complexity=\"standard\", batch_size=64, epochs=10):\n",
    "    \"\"\"Treinar modelo LSTM com validação cruzada k-fold.\n",
    "    \n",
    "    Args:\n",
    "        X: Sequências com padding\n",
    "        y: Rótulos alvo\n",
    "        vocab_size: Tamanho do vocabulário\n",
    "        embedding_dim: Dimensão da camada de embedding\n",
    "        max_len: Comprimento máximo das sequências de entrada\n",
    "        n_folds: Número de folds para validação cruzada\n",
    "        complexity: Nível de complexidade do modelo (\"light\", \"standard\", \"deep\")\n",
    "        batch_size: Tamanho do batch para treino\n",
    "        epochs: Número máximo de épocas para treino\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (models, histories, scores, metrics_df)\n",
    "    \"\"\"\n",
    "    print(f\"Treinando com validação cruzada {n_folds}-fold...\")\n",
    "    \n",
    "    # Converter para arrays numpy se forem Series pandas\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.values\n",
    "    \n",
    "    # Definir estratégia de validação cruzada\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Listas para armazenar resultados\n",
    "    models = []\n",
    "    histories = []\n",
    "    scores = []\n",
    "    fold_metrics = []\n",
    "    \n",
    "    # Ajustar batch_size baseado no tamanho dos dados\n",
    "    if len(X) < 1000:\n",
    "        batch_size = min(batch_size, 32)  # Batch menor para datasets pequenos\n",
    "        print(f\"Ajustando batch_size para {batch_size} devido ao tamanho do dataset\")\n",
    "    \n",
    "    # Loop de validação cruzada\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "        print(f\"\\nTreinando fold {fold+1}/{n_folds}\")\n",
    "        \n",
    "        # Dividir dados\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Construir modelo\n",
    "        model = build_lstm_model(vocab_size, embedding_dim, max_len, complexity)\n",
    "        \n",
    "        # Definir callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        checkpoint_path = f\"/tmp/lstm_model_fold_{fold+1}.keras\"\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            checkpoint_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            mode='min'\n",
    "        )\n",
    "        \n",
    "        # Registrar tempo de início\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Treinar modelo\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            callbacks=[early_stopping, model_checkpoint],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Calcular tempo de treino\n",
    "        train_time = time.time() - start_time\n",
    "        print(f\"Tempo de treino: {train_time:.2f} segundos\")\n",
    "        \n",
    "        # Avaliar modelo\n",
    "        score = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        print(f\"Fold {fold+1} - Loss: {score[0]:.4f}, Accuracy: {score[1]:.4f}\")\n",
    "        \n",
    "        # Previsões\n",
    "        y_pred_proba = model.predict(X_val_fold)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        precision = precision_score(y_val_fold, y_pred, average='weighted')\n",
    "        recall = recall_score(y_val_fold, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_val_fold, y_pred, average='weighted')\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'fold': fold+1,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'train_time': train_time\n",
    "        })\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "        scores.append(score[1])  # Accuracy\n",
    "        \n",
    "        # Copiar modelo para DBFS\n",
    "        dbutils.fs.cp(f\"file:{checkpoint_path}\", f\"dbfs:/FileStore/fake_news_detection/models/lstm/cv_folds/lstm_model_fold_{fold+1}.keras\")\n",
    "        \n",
    "        # Liberar memória\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Imprimir desempenho médio\n",
    "    print(f\"\\nValidação cruzada completa. Accuracy média: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "    \n",
    "    # Criar DataFrame com métricas por fold\n",
    "    metrics_df = pd.DataFrame(fold_metrics)\n",
    "    print(\"\\nMétricas por fold:\")\n",
    "    print(metrics_df)\n",
    "    \n",
    "    # Salvar métricas em CSV\n",
    "    metrics_csv_path = \"/tmp/lstm_cv_metrics.csv\"\n",
    "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "    dbutils.fs.cp(f\"file:{metrics_csv_path}\", \"dbfs:/FileStore/fake_news_detection/logs/lstm_cv_metrics.csv\")\n",
    "    \n",
    "    return models, histories, scores, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar Modelo Final\n",
    "\n",
    "Treinar um modelo final no conjunto de treino completo após a validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(X_train, y_train, X_test, y_test, vocab_size, embedding_dim=100, max_len=300, complexity=\"standard\", batch_size=64, epochs=10):\n",
    "    \"\"\"Treinar modelo final no conjunto de treino completo após validação cruzada.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Sequências de treino com padding\n",
    "        y_train: Rótulos de treino\n",
    "        X_test: Sequências de teste com padding\n",
    "        y_test: Rótulos de teste\n",
    "        vocab_size: Tamanho do vocabulário\n",
    "        embedding_dim: Dimensão da camada de embedding\n",
    "        max_len: Comprimento máximo das sequências de entrada\n",
    "        complexity: Nível de complexidade do modelo (\"light\", \"standard\", \"deep\")\n",
    "        batch_size: Tamanho do batch para treino\n",
    "        epochs: Número máximo de épocas para treino\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, history, test_metrics)\n",
    "    \"\"\"\n",
    "    print(\"\\nTreinando modelo final no conjunto de treino completo...\")\n",
    "    \n",
    "    # Construir modelo\n",
    "    model = build_lstm_model(vocab_size, embedding_dim, max_len, complexity)\n",
    "    \n",
    "    # Definir callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    checkpoint_path = \"/tmp/lstm_model_final.keras\"\n",
    "    model_checkpoint = ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    \n",
    "    # Registrar tempo de início\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Treinar modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.1,  # 10% para validação\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Calcular tempo de treino\n",
    "    train_time = time.time() - start_time\n",
    "    print(f\"Tempo de treino: {train_time:.2f} segundos\")\n",
    "    \n",
    "    # Avaliar no conjunto de teste\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Accuracy no teste: {test_acc:.4f}\")\n",
    "    \n",
    "    # Previsões\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Relatório de classificação\n",
    "    print(\"\\nRelatório de classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "    plt.xlabel('Previsto')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar figura\n",
    "    cm_path = \"/tmp/confusion_matrix.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    dbutils.fs.cp(f\"file:{cm_path}\", \"dbfs:/FileStore/fake_news_detection/logs/lstm_confusion_matrix.png\")\n",
    "    \n",
    "    # Salvar modelo final\n",
    "    dbutils.fs.cp(f\"file:{checkpoint_path}\", \"dbfs:/FileStore/fake_news_detection/models/lstm/lstm_model_final.keras\")\n",
    "    \n",
    "    # Métricas de teste\n",
    "    test_metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'train_time': train_time\n",
    "    }\n",
    "    \n",
    "    return model, history, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar Histórico de Treino\n",
    "\n",
    "Visualizar o histórico de treino para analisar o desempenho do modelo ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Visualizar histórico de treino do modelo.\n",
    "    \n",
    "    Args:\n",
    "        history: Objeto history retornado por model.fit()\n",
    "    \"\"\"\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Accuracy do Modelo')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Treino', 'Validação'], loc='lower right')\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Loss do Modelo')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Época')\n",
    "    plt.legend(['Treino', 'Validação'], loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar figura\n",
    "    history_path = \"/tmp/training_history.png\"\n",
    "    plt.savefig(history_path)\n",
    "    dbutils.fs.cp(f\"file:{history_path}\", \"dbfs:/FileStore/fake_news_detection/logs/lstm_training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar Tokenizer\n",
    "\n",
    "Salvar o tokenizer para uso futuro na inferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer):\n",
    "    \"\"\"Salvar tokenizer para uso futuro na inferência.\n",
    "    \n",
    "    Args:\n",
    "        tokenizer: Objeto tokenizer treinado\n",
    "    \"\"\"\n",
    "    tokenizer_path = \"/tmp/tokenizer.pickle\"\n",
    "    with open(tokenizer_path, 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    dbutils.fs.cp(f\"file:{tokenizer_path}\", \"dbfs:/FileStore/fake_news_detection/models/lstm/tokenizer.pickle\")\n",
    "    print(\"Tokenizer salvo em dbfs:/FileStore/fake_news_detection/models/lstm/tokenizer.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função Principal\n",
    "\n",
    "Função principal para executar o pipeline completo de treino LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(use_sample=True, sample_size_per_class=5000, complexity=\"light\", n_folds=3):\n",
    "    \"\"\"Executar pipeline completo de treino LSTM.\n",
    "    \n",
    "    Args:\n",
    "        use_sample: Se True, usa amostragem estratificada para treino com recursos limitados\n",
    "        sample_size_per_class: Número de registros por classe para a amostra\n",
    "        complexity: Nível de complexidade do modelo (\"light\", \"standard\", \"deep\")\n",
    "        n_folds: Número de folds para validação cruzada\n",
    "    \"\"\"\n",
    "    print(\"Iniciando pipeline de treino LSTM para deteção de notícias falsas...\")\n",
    "    \n",
    "    # Criar estrutura de diretórios\n",
    "    create_directory_structure()\n",
    "    \n",
    "    # Inicializar Spark\n",
    "    spark = initialize_spark()\n",
    "    \n",
    "    # Carregar dados\n",
    "    df = load_data(spark, use_sample=use_sample, sample_size_per_class=sample_size_per_class)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Converter para Pandas para processamento\n",
    "    print(\"\\nConvertendo para DataFrame Pandas...\")\n",
    "    pandas_df = df.toPandas()\n",
    "    \n",
    "    # Preparar dados de texto\n",
    "    X_train_pad, X_test_pad, y_train, y_test, tokenizer = prepare_text_data(pandas_df)\n",
    "    \n",
    "    # Tamanho do vocabulário\n",
    "    vocab_size = min(len(tokenizer.word_index) + 1, 20000)\n",
    "    \n",
    "    # Treinar com validação cruzada\n",
    "    models, histories, scores, metrics_df = train_with_cross_validation(\n",
    "        X_train_pad, y_train, vocab_size, \n",
    "        n_folds=n_folds, \n",
    "        complexity=complexity,\n",
    "        batch_size=32 if use_sample and sample_size_per_class < 1000 else 64\n",
    "    )\n",
    "    \n",
    "    # Treinar modelo final\n",
    "    final_model, final_history, test_metrics = train_final_model(\n",
    "        X_train_pad, y_train, X_test_pad, y_test, vocab_size,\n",
    "        complexity=complexity,\n",
    "        batch_size=32 if use_sample and sample_size_per_class < 1000 else 64\n",
    "    )\n",
    "    \n",
    "    # Visualizar histórico de treino\n",
    "    plot_training_history(final_history)\n",
    "    \n",
    "    # Salvar tokenizer\n",
    "    save_tokenizer(tokenizer)\n",
    "    \n",
    "    print(\"\\nPipeline de treino LSTM concluído com sucesso!\")\n",
    "    print(f\"Modelo final salvo em dbfs:/FileStore/fake_news_detection/models/lstm/lstm_model_final.keras\")\n",
    "    print(f\"Métricas de teste: {test_metrics}\")\n",
    "    \n",
    "    # Liberar memória\n",
    "    spark.stop()\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executar Pipeline\n",
    "\n",
    "Executar o pipeline completo de treino LSTM com configurações apropriadas para a Databricks Community Edition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações recomendadas para Databricks Community Edition (15.3 GB Memory, 2 Cores)\n",
    "main(\n",
    "    use_sample=True,           # Usar amostragem para Community Edition\n",
    "    sample_size_per_class=2000, # 2000 exemplos por classe (ajuste conforme necessário)\n",
    "    complexity=\"light\",        # Modelo mais leve para recursos limitados\n",
    "    n_folds=3                  # Menos folds para validação cruzada mais rápida\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações Alternativas\n",
    "\n",
    "Abaixo estão configurações alternativas para diferentes cenários de recursos. Descomente a configuração apropriada para o seu ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configuração para recursos moderados (ex: cluster com mais memória)\n",
    "# main(\n",
    "#     use_sample=True,\n",
    "#     sample_size_per_class=5000,  # Amostra maior\n",
    "#     complexity=\"standard\",       # Modelo padrão\n",
    "#     n_folds=5                    # Mais folds para validação mais robusta\n",
    "# )\n",
    "\n",
    "# # Configuração para recursos abundantes (ex: cluster com GPUs)\n",
    "# main(\n",
    "#     use_sample=False,            # Usar dataset completo\n",
    "#     complexity=\"deep\",           # Modelo mais profundo\n",
    "#     n_folds=5                    # Validação cruzada completa\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook demonstrou como implementar, treinar e avaliar um modelo LSTM para deteção de notícias falsas, com considerações específicas para as limitações da Databricks Community Edition.\n",
    "\n",
    "### Principais pontos:\n",
    "\n",
    "1. **Amostragem estratificada**: Usada para lidar com limitações de memória, mantendo a distribuição de classes\n",
    "2. **Validação cruzada**: Implementada para avaliação robusta mesmo com amostras menores\n",
    "3. **Complexidade ajustável**: Opções para modelos mais leves ou mais profundos dependendo dos recursos disponíveis\n",
    "4. **Gestão de memória**: Técnicas para liberar memória e evitar problemas de OOM (Out of Memory)\n",
    "\n",
    "### Próximos passos:\n",
    "\n",
    "1. Experimentar com diferentes arquiteturas (GRU, Transformers)\n",
    "2. Implementar técnicas de regularização adicionais\n",
    "3. Explorar embeddings pré-treinados (GloVe, Word2Vec)\n",
    "4. Desenvolver um pipeline de inferência para classificação em tempo real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
