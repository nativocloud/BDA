{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720ee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM and deep learning utility functions for fake news detection project.\n",
    "This module contains functions for creating and training LSTM models.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c307b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_list\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bb0d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def spark_df_to_pandas(spark_df, text_col=\"text\", label_col=\"label\"):\n",
    "    \"\"\"\n",
    "    Convert Spark DataFrame to Pandas DataFrame for deep learning.\n",
    "    \n",
    "    Args:\n",
    "        spark_df: Spark DataFrame\n",
    "        text_col (str): Column containing text data\n",
    "        label_col (str): Column containing labels\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    # Collect data from Spark DataFrame\n",
    "    pandas_df = spark_df.select(text_col, label_col).toPandas()\n",
    "    \n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdaf53",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_text_data(texts, max_features=10000, max_len=200):\n",
    "    \"\"\"\n",
    "    Prepare text data for LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of text documents\n",
    "        max_features (int): Maximum number of words to keep\n",
    "        max_len (int): Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (tokenizer, sequences)\n",
    "    \"\"\"\n",
    "    # Create tokenizer\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    # Convert texts to sequences\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "    \n",
    "    return tokenizer, padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf29ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(max_features=10000, embedding_dim=128, max_len=200):\n",
    "    \"\"\"\n",
    "    Create an LSTM model for text classification.\n",
    "    \n",
    "    Args:\n",
    "        max_features (int): Maximum number of words to keep\n",
    "        embedding_dim (int): Dimension of the embedding layer\n",
    "        max_len (int): Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        tf.keras.Model: LSTM model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding layer\n",
    "    model.add(Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=max_len))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0fd53",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_lstm_model(model, X_train, y_train, X_val, y_val, batch_size=64, epochs=10, model_path=None):\n",
    "    \"\"\"\n",
    "    Train an LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        model: LSTM model\n",
    "        X_train: Training data\n",
    "        y_train: Training labels\n",
    "        X_val: Validation data\n",
    "        y_val: Validation labels\n",
    "        batch_size (int): Batch size\n",
    "        epochs (int): Number of epochs\n",
    "        model_path (str): Path to save the model\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (trained_model, history)\n",
    "    \"\"\"\n",
    "    # Define callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    # Add model checkpoint if path is provided\n",
    "    if model_path:\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        callbacks.append(ModelCheckpoint(model_path, save_best_only=True))\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4dd78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_lstm_model(model, X_test, y_test, log_dir=None):\n",
    "    \"\"\"\n",
    "    Evaluate an LSTM model.\n",
    "    \n",
    "    Args:\n",
    "        model: LSTM model\n",
    "        X_test: Test data\n",
    "        y_test: Test labels\n",
    "        log_dir (str): Directory to save evaluation logs\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    \n",
    "    # Create metrics dictionary\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    if log_dir:\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        with open(os.path.join(log_dir, \"lstm_evaluation_metrics.txt\"), \"w\") as f:\n",
    "            f.write(f\"LSTM Model Evaluation\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "            f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "            f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "            f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "            f.write(\"\\nClassification Report:\\n\")\n",
    "            f.write(classification_report(y_test, y_pred))\n",
    "            f.write(\"\\nConfusion Matrix:\\n\")\n",
    "            f.write(str(confusion_matrix(y_test, y_pred)))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af0e6b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_lstm_model(model, tokenizer, model_path, tokenizer_path):\n",
    "    \"\"\"\n",
    "    Save LSTM model and tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        model: LSTM model\n",
    "        tokenizer: Tokenizer\n",
    "        model_path (str): Path to save the model\n",
    "        tokenizer_path (str): Path to save the tokenizer\n",
    "    \"\"\"\n",
    "    # Save model\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    # Save tokenizer\n",
    "    os.makedirs(os.path.dirname(tokenizer_path), exist_ok=True)\n",
    "    import pickle\n",
    "    with open(tokenizer_path, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    print(f\"Tokenizer saved to {tokenizer_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lstm_model(model_path, tokenizer_path):\n",
    "    \"\"\"\n",
    "    Load LSTM model and tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to the saved model\n",
    "        tokenizer_path (str): Path to the saved tokenizer\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (model, tokenizer)\n",
    "    \"\"\"\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    # Load tokenizer\n",
    "    import pickle\n",
    "    with open(tokenizer_path, 'rb') as f:\n",
    "        tokenizer = pickle.load(f)\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Tokenizer loaded from {tokenizer_path}\")\n",
    "    \n",
    "    return model, tokenizer"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
