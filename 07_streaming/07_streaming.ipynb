{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4395c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script to demonstrate a minimal streaming pipeline for fake news detection.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bebff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acb5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = \"/home/ubuntu/fake_news_detection/data\"\n",
    "models_dir = \"/home/ubuntu/fake_news_detection/models\"\n",
    "results_dir = \"/home/ubuntu/fake_news_detection/logs\"\n",
    "stream_dir = \"/home/ubuntu/fake_news_detection/data/streaming\"\n",
    "output_dir = \"/home/ubuntu/fake_news_detection/data/streaming_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c23523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "os.makedirs(stream_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d564c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model and vectorizer...\")\n",
    "# Load the trained model and vectorizer\n",
    "with open(f\"{models_dir}/rf_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "with open(f\"{models_dir}/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad31d7d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"Loading streaming sample data...\")\n",
    "# Load the streaming sample data\n",
    "stream_sample = pd.read_csv(f\"{data_dir}/stream_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fb281",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to process a batch of data\n",
    "def process_batch(batch_df, batch_id):\n",
    "    print(f\"Processing batch {batch_id}...\")\n",
    "    \n",
    "    # Preprocess text\n",
    "    if 'title' in batch_df.columns and 'text' in batch_df.columns:\n",
    "        batch_df['content'] = batch_df['title'].fillna('') + \" \" + batch_df['text'].fillna('')\n",
    "    else:\n",
    "        batch_df['content'] = batch_df['text'].fillna('')\n",
    "    \n",
    "    batch_df['content'] = batch_df['content'].str.lower()\n",
    "    \n",
    "    # Extract features\n",
    "    X = vectorizer.transform(batch_df['content'])\n",
    "    \n",
    "    # Make predictions\n",
    "    batch_df['prediction'] = model.predict(X)\n",
    "    batch_df['prediction_proba'] = model.predict_proba(X)[:, 1]\n",
    "    batch_df['prediction_time'] = pd.Timestamp.now()\n",
    "    \n",
    "    # Save batch results\n",
    "    output_file = f\"{output_dir}/batch_{batch_id}_results.csv\"\n",
    "    batch_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Return batch results for aggregation\n",
    "    return batch_df[['id', 'prediction', 'prediction_proba', 'prediction_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ddf71",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to simulate streaming\n",
    "def simulate_streaming(stream_df, batch_size=5, delay_seconds=2):\n",
    "    print(f\"Starting streaming simulation with {len(stream_df)} records...\")\n",
    "    \n",
    "    # Split data into batches\n",
    "    num_batches = len(stream_df) // batch_size + (1 if len(stream_df) % batch_size > 0 else 0)\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        # Get batch\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(stream_df))\n",
    "        batch = stream_df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # Save batch to streaming directory\n",
    "        batch_file = f\"{stream_dir}/batch_{i}.csv\"\n",
    "        batch.to_csv(batch_file, index=False)\n",
    "        print(f\"Saved batch {i} to {batch_file}\")\n",
    "        \n",
    "        # Process batch\n",
    "        batch_results = process_batch(batch, i)\n",
    "        all_results.append(batch_results)\n",
    "        \n",
    "        # Simulate delay between batches\n",
    "        if i < num_batches - 1:\n",
    "            print(f\"Waiting {delay_seconds} seconds before next batch...\")\n",
    "            time.sleep(delay_seconds)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run streaming simulation\n",
    "results = simulate_streaming(stream_sample, batch_size=5, delay_seconds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(\"\\nStreaming Results Summary:\")\n",
    "print(f\"Total records processed: {len(results)}\")\n",
    "print(f\"Fake news detected: {len(results[results['prediction'] == 0])}\")\n",
    "print(f\"Real news detected: {len(results[results['prediction'] == 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated results\n",
    "results.to_csv(f\"{output_dir}/aggregated_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49299e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='prediction', data=results)\n",
    "plt.title('Streaming Predictions')\n",
    "plt.xlabel('Prediction (0=Fake, 1=Real)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(f\"{results_dir}/streaming_predictions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series visualization\n",
    "results['prediction_time'] = pd.to_datetime(results['prediction_time'])\n",
    "results = results.sort_values('prediction_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ada41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by minute and count predictions\n",
    "time_series = results.set_index('prediction_time').resample('1S').prediction.value_counts().unstack().fillna(0)\n",
    "if 0 not in time_series.columns:\n",
    "    time_series[0] = 0\n",
    "if 1 not in time_series.columns:\n",
    "    time_series[1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07050e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "time_series.plot(figsize=(12, 6))\n",
    "plt.title('Predictions Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Fake', 'Real'])\n",
    "plt.savefig(f\"{results_dir}/streaming_time_series.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for Grafana\n",
    "streaming_metrics = {\n",
    "    \"total_processed\": len(results),\n",
    "    \"fake_count\": int(len(results[results['prediction'] == 0])),\n",
    "    \"real_count\": int(len(results[results['prediction'] == 1])),\n",
    "    \"fake_percentage\": float(len(results[results['prediction'] == 0]) / len(results) * 100),\n",
    "    \"real_percentage\": float(len(results[results['prediction'] == 1]) / len(results) * 100),\n",
    "    \"execution_time\": time.time() - start_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29aa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{results_dir}/streaming_metrics.json\", \"w\") as f:\n",
    "    json.dump(streaming_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b03ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dashboard-like visualization\n",
    "plt.figure(figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c67fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions count\n",
    "plt.subplot(2, 2, 1)\n",
    "labels = ['Fake News', 'Real News']\n",
    "sizes = [streaming_metrics['fake_count'], streaming_metrics['real_count']]\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])\n",
    "plt.axis('equal')\n",
    "plt.title('Prediction Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b84086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction probabilities histogram\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(results['prediction_proba'], bins=10)\n",
    "plt.title('Prediction Probability Distribution')\n",
    "plt.xlabel('Probability of being Real News')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series\n",
    "plt.subplot(2, 2, 3)\n",
    "time_series.plot(ax=plt.gca())\n",
    "plt.title('Predictions Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(['Fake', 'Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a645c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary text\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "Streaming Pipeline Summary:\n",
    "---------------------------\n",
    "Total records processed: {streaming_metrics['total_processed']}\n",
    "Fake news detected: {streaming_metrics['fake_count']} ({streaming_metrics['fake_percentage']:.1f}%)\n",
    "Real news detected: {streaming_metrics['real_count']} ({streaming_metrics['real_percentage']:.1f}%)\n",
    "Execution time: {streaming_metrics['execution_time']:.2f} seconds\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, summary_text, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513dfebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(f\"{results_dir}/streaming_dashboard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9606e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nStreaming simulation completed in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"Results saved to {output_dir}\")\n",
    "print(f\"Visualizations saved to {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Last modified: May 29, 2025
